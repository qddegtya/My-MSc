{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 03 内容分析：情感、叙事与政治立场\n",
    "\n",
    "**研究核心**: Charlie Kirk政治暗杀事件后72小时的社交媒体舆论内容分析\n",
    "\n",
    "**分析维度**:\n",
    "1. **6维情感分析**: sadness, anger, fear, surprise, disgust, joy\n",
    "2. **6大叙事框架**: 政治暴力受害者、言论后果、政治极化、言论自由、阴谋论、纪念遗产\n",
    "3. **政治立场分类**: conservative, liberal, neutral\n",
    "4. **时间演变**: 情感与叙事随72小时的变化\n",
    "5. **代表性内容**: 每类叙事的典型推文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python 路径已配置: /workspace\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 将项目根目录添加到 Python 路径\n",
    "project_root = Path('/workspace')\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "print(f\"✅ Python 路径已配置: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 步骤 1: 加载数据并采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据加载完成: 508,954 行\n",
      "📝 有效英文推文: 415,714 条\n",
      "  48-72h: 415,714 条 → 采样 2,000 条\n",
      "\n",
      "📋 采样完成: 2,000 条推文\n",
      "\n",
      "时间窗口分布:\n",
      "shape: (1, 2)\n",
      "┌─────────────┬───────┐\n",
      "│ time_window ┆ count │\n",
      "│ ---         ┆ ---   │\n",
      "│ str         ┆ u32   │\n",
      "╞═════════════╪═══════╡\n",
      "│ 48-72h      ┆ 2000  │\n",
      "└─────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 加载enriched数据（包含event_time_delta_hours和time_window字段）\n",
    "df = pl.read_parquet(\"../parquet/tweets_enriched.parquet\")\n",
    "print(f\"📊 数据加载完成: {df.height:,} 行\")\n",
    "\n",
    "# 过滤有效英文文本\n",
    "df_text = df.filter(\n",
    "    (pl.col('text').is_not_null()) & \n",
    "    (pl.col('lang') == 'en') &\n",
    "    (pl.col('text').str.len_chars() > 20)  # 至少20字符\n",
    ")\n",
    "print(f\"📝 有效英文推文: {df_text.height:,} 条\")\n",
    "\n",
    "# 采样策略：每个时间窗口采样最多2000条（确保时间演变分析的代表性）\n",
    "sample_per_window = 2000\n",
    "\n",
    "# 方法：对每个时间窗口分别采样后合并\n",
    "sampled_dfs = []\n",
    "for window in df_text['time_window'].unique().sort():\n",
    "    window_df = df_text.filter(pl.col('time_window') == window)\n",
    "    # 如果该窗口数据少于2000，全部使用；否则采样2000\n",
    "    n_sample = min(sample_per_window, window_df.height)\n",
    "    sampled = window_df.sample(n=n_sample, seed=42)\n",
    "    sampled_dfs.append(sampled)\n",
    "    print(f\"  {window}: {window_df.height:,} 条 → 采样 {n_sample:,} 条\")\n",
    "\n",
    "df_sample = pl.concat(sampled_dfs).sort('createdAt')\n",
    "\n",
    "print(f\"\\n📋 采样完成: {df_sample.height:,} 条推文\")\n",
    "print(f\"\\n时间窗口分布:\")\n",
    "print(df_sample.group_by('time_window').agg(pl.len().alias('count')).sort('time_window'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotion_header",
   "metadata": {},
   "source": [
    "## 步骤 2: 六维情感分析\n",
    "\n",
    "使用 HuggingFace `j-hartmann/emotion-english-distilroberta-base` 模型  \n",
    "分类：sadness, joy, love, anger, fear, surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emotion_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 加载情感分析模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型加载完成 (device: CPU)\n",
      "\n",
      "🔄 开始情感分析 (2,000 条推文)...\n",
      "✅ 情感分析完成\n",
      "\n",
      "📊 情感分布:\n",
      "shape: (7, 2)\n",
      "┌─────────────────┬───────┐\n",
      "│ primary_emotion ┆ count │\n",
      "│ ---             ┆ ---   │\n",
      "│ str             ┆ u32   │\n",
      "╞═════════════════╪═══════╡\n",
      "│ anger           ┆ 463   │\n",
      "│ neutral         ┆ 449   │\n",
      "│ fear            ┆ 394   │\n",
      "│ sadness         ┆ 268   │\n",
      "│ surprise        ┆ 207   │\n",
      "│ joy             ┆ 141   │\n",
      "│ disgust         ┆ 78    │\n",
      "└─────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(\"🤖 加载情感分析模型...\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    device=device,\n",
    "    top_k=None  # 返回所有情感的概率\n",
    ")\n",
    "\n",
    "print(f\"✅ 模型加载完成 (device: {'GPU' if device == 0 else 'CPU'})\")\n",
    "\n",
    "# 处理文本（批量推理）\n",
    "texts = df_sample['text'].to_list()\n",
    "print(f\"\\n🔄 开始情感分析 ({len(texts):,} 条推文)...\")\n",
    "\n",
    "# 批量处理，每批128条\n",
    "batch_size = 128\n",
    "all_emotions = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    # 截断长文本\n",
    "    batch_truncated = [t[:512] for t in batch]\n",
    "    results = emotion_classifier(batch_truncated)\n",
    "    all_emotions.extend(results)\n",
    "    \n",
    "    if (i + batch_size) % 1000 == 0:\n",
    "        print(f\"  处理进度: {i + batch_size:,} / {len(texts):,}\")\n",
    "\n",
    "print(f\"✅ 情感分析完成\")\n",
    "\n",
    "# 提取主要情感和置信度\n",
    "primary_emotions = [max(e, key=lambda x: x['score'])['label'] for e in all_emotions]\n",
    "primary_scores = [max(e, key=lambda x: x['score'])['score'] for e in all_emotions]\n",
    "\n",
    "# 提取6大情感的分数（构建情感向量）\n",
    "emotion_labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "emotion_vectors = {}\n",
    "for label in emotion_labels:\n",
    "    scores = []\n",
    "    for result in all_emotions:\n",
    "        score_dict = {item['label']: item['score'] for item in result}\n",
    "        scores.append(score_dict.get(label, 0.0))\n",
    "    emotion_vectors[f'emotion_{label}'] = scores\n",
    "\n",
    "# 添加到dataframe\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('primary_emotion', primary_emotions),\n",
    "    pl.Series('emotion_confidence', primary_scores),\n",
    "    *[pl.Series(k, v) for k, v in emotion_vectors.items()]\n",
    "])\n",
    "\n",
    "print(f\"\\n📊 情感分布:\")\n",
    "print(df_sample.group_by('primary_emotion').agg(pl.len().alias('count')).sort('count', descending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative_header",
   "metadata": {},
   "source": [
    "## 步骤 3: 六大叙事框架检测\n",
    "\n",
    "基于关键词和语义相似度的叙事分类：\n",
    "1. **political_violence**: 政治暴力受害者叙事\n",
    "2. **consequences**: 言论后果叙事\n",
    "3. **polarization**: 政治极化叙事\n",
    "4. **free_speech**: 言论自由叙事\n",
    "5. **conspiracy**: 阴谋论叙事\n",
    "6. **memorial**: 纪念与遗产叙事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "narrative_keywords",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 加载语义模型用于叙事检测...\n",
      "🔢 生成叙事框架语义向量...\n",
      "🔍 开始基于语义的叙事框架检测...\n",
      "  (使用sentence embeddings + 关键词增强)\n",
      "\n",
      "🔢 生成推文语义向量 (2,000 条)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 检测叙事框架...\n",
      "  处理进度: 2,000 / 2,000\n",
      "\n",
      "✅ 叙事框架检测完成\n",
      "\n",
      "📊 叙事分布:\n",
      "shape: (7, 2)\n",
      "┌────────────────────┬───────┐\n",
      "│ primary_narrative  ┆ count │\n",
      "│ ---                ┆ ---   │\n",
      "│ str                ┆ u32   │\n",
      "╞════════════════════╪═══════╡\n",
      "│ political_violence ┆ 950   │\n",
      "│ memorial           ┆ 660   │\n",
      "│ none               ┆ 236   │\n",
      "│ free_speech        ┆ 68    │\n",
      "│ consequences       ┆ 42    │\n",
      "│ conspiracy         ┆ 35    │\n",
      "│ polarization       ┆ 9     │\n",
      "└────────────────────┴───────┘\n",
      "\n",
      "📈 平均置信度: 0.464\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"🤖 加载语义模型用于叙事检测...\")\n",
    "# 复用之前的模型或加载轻量级模型\n",
    "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 定义6大叙事框架的原型文本（核心语义描述）\n",
    "narrative_prototypes = {\n",
    "    'political_violence': [\n",
    "        \"This is a tragic political assassination and act of violence\",\n",
    "        \"Charlie Kirk was a victim of political violence and murder\",\n",
    "        \"The shooting was a terrible attack on a political figure\",\n",
    "        \"This assassination is an act of terror against conservatives\"\n",
    "    ],\n",
    "    'consequences': [\n",
    "        \"His hateful rhetoric had dangerous consequences\",\n",
    "        \"This is the result of divisive and toxic speech\",\n",
    "        \"He deserves blame for spreading hate and division\",\n",
    "        \"His inflammatory words caused this violence\"\n",
    "    ],\n",
    "    'polarization': [\n",
    "        \"America is deeply divided and polarized\",\n",
    "        \"This shows our country is on the brink of civil war\",\n",
    "        \"We treat each other as enemies instead of fellow citizens\",\n",
    "        \"Political tribalism is tearing our nation apart\"\n",
    "    ],\n",
    "    'free_speech': [\n",
    "        \"This is an attack on free speech and open debate\",\n",
    "        \"They are trying to silence conservative voices\",\n",
    "        \"We must defend the right to express political views\",\n",
    "        \"Censorship and suppression of speech led to this\"\n",
    "    ],\n",
    "    'conspiracy': [\n",
    "        \"This was a false flag operation and setup\",\n",
    "        \"The deep state planned this assassination\",\n",
    "        \"This is a psyop to manipulate public opinion\",\n",
    "        \"The official story is fake and a coverup\"\n",
    "    ],\n",
    "    'memorial': [\n",
    "        \"We honor and remember Charlie Kirk's legacy\",\n",
    "        \"His impact on conservative youth will not be forgotten\",\n",
    "        \"Rest in peace, he made a difference in politics\",\n",
    "        \"We pay tribute to his memory and contributions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 生成叙事原型的embeddings（每个叙事用其原型文本的平均embedding）\n",
    "print(\"🔢 生成叙事框架语义向量...\")\n",
    "narrative_embeddings = {}\n",
    "for narrative, prototype_texts in narrative_prototypes.items():\n",
    "    proto_embs = semantic_model.encode(prototype_texts)\n",
    "    # 使用平均向量作为该叙事的代表\n",
    "    narrative_embeddings[narrative] = np.mean(proto_embs, axis=0)\n",
    "\n",
    "# 关键词辅助（用于增强confidence）\n",
    "narrative_keywords = {\n",
    "    'political_violence': [\n",
    "        r'\\bvictim\\b', r'\\btragedy\\b', r'\\bassassinat\\w*\\b', r'\\bviolence\\b', \n",
    "        r'\\bmurder\\w*\\b', r'\\bkill\\w*\\b', r'\\bshot\\b', r'\\bshooting\\b',\n",
    "        r'\\bterror\\w*\\b', r'\\bgunman\\b', r'\\battack\\w*\\b'\n",
    "    ],\n",
    "    'consequences': [\n",
    "        r'\\brhetoric\\b', r'\\bconsequences\\b', r'\\bhate speech\\b', r'\\bdivisive\\b',\n",
    "        r'\\bresponsib\\w*\\b', r'\\bblame\\b', r'\\bcaused\\b', r'\\bdeserve\\w*\\b',\n",
    "        r'\\bkarma\\b', r'\\breap\\w*\\b'\n",
    "    ],\n",
    "    'polarization': [\n",
    "        r'\\bdivided\\b', r'\\bpolari\\w*\\b', r'\\bcivil war\\b', r'\\benemy\\b',\n",
    "        r'\\bus vs them\\b', r'\\btear\\w* apart\\b', r'\\bpartisan\\b'\n",
    "    ],\n",
    "    'free_speech': [\n",
    "        r'\\bfree speech\\b', r'\\bsilenc\\w*\\b', r'\\bcensor\\w*\\b', r'\\bdebate\\b',\n",
    "        r'\\bfirst amendment\\b', r'\\bvoice\\b', r'\\bspeak\\w* out\\b'\n",
    "    ],\n",
    "    'conspiracy': [\n",
    "        r'\\bfalse flag\\b', r'\\bsetup\\b', r'\\bdeep state\\b', r'\\bpsyop\\b',\n",
    "        r'\\bcoverup\\b', r'\\bcover-up\\b', r'\\bplanned\\b', r'\\binside job\\b',\n",
    "        r'\\bfake\\b', r'\\bhoax\\b'\n",
    "    ],\n",
    "    'memorial': [\n",
    "        r'\\blegacy\\b', r'\\bremember\\b', r'\\bhonor\\b', r'\\bimpact\\b',\n",
    "        r'\\bRIP\\b', r'\\brest in peace\\b', r'\\bmemory\\b', r'\\bmemorial\\b',\n",
    "        r'\\btribute\\b', r'\\bmiss\\w*\\b'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def detect_narratives_semantic(text, text_embedding):\n",
    "    \"\"\"基于语义相似度 + 关键词增强的叙事检测\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    narrative_scores = {}\n",
    "    \n",
    "    for narrative in narrative_prototypes.keys():\n",
    "        # 1. 语义相似度分数（主要）\n",
    "        similarity = cosine_similarity(\n",
    "            text_embedding.reshape(1, -1),\n",
    "            narrative_embeddings[narrative].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        \n",
    "        # 2. 关键词匹配分数（辅助增强）\n",
    "        keyword_matches = sum(1 for pattern in narrative_keywords[narrative] \n",
    "                             if re.search(pattern, text_lower))\n",
    "        keyword_boost = keyword_matches * 0.05  # 每个关键词增加5%\n",
    "        \n",
    "        # 综合分数：语义相似度为主，关键词提供boost\n",
    "        final_score = similarity + keyword_boost\n",
    "        narrative_scores[narrative] = final_score\n",
    "    \n",
    "    return narrative_scores\n",
    "\n",
    "print(\"🔍 开始基于语义的叙事框架检测...\")\n",
    "print(\"  (使用sentence embeddings + 关键词增强)\")\n",
    "\n",
    "# 生成所有推文的embeddings（批量处理）\n",
    "print(f\"\\n🔢 生成推文语义向量 ({len(texts):,} 条)...\")\n",
    "tweet_embeddings = semantic_model.encode(texts, show_progress_bar=True, batch_size=128)\n",
    "\n",
    "# 对每条推文进行叙事检测\n",
    "print(\"\\n🎯 检测叙事框架...\")\n",
    "narrative_results = []\n",
    "for i, (text, embedding) in enumerate(zip(texts, tweet_embeddings)):\n",
    "    scores = detect_narratives_semantic(text, embedding)\n",
    "    narrative_results.append(scores)\n",
    "    \n",
    "    if (i + 1) % 2000 == 0:\n",
    "        print(f\"  处理进度: {i + 1:,} / {len(texts):,}\")\n",
    "\n",
    "# 提取主导叙事（得分最高的，且高于阈值0.3）\n",
    "primary_narratives = []\n",
    "narrative_confidences = []\n",
    "for scores in narrative_results:\n",
    "    max_narrative = max(scores, key=scores.get)\n",
    "    max_score = scores[max_narrative]\n",
    "    \n",
    "    if max_score > 0.3:  # 置信度阈值\n",
    "        primary_narratives.append(max_narrative)\n",
    "        narrative_confidences.append(max_score)\n",
    "    else:\n",
    "        primary_narratives.append('none')  # 无明显叙事\n",
    "        narrative_confidences.append(0.0)\n",
    "\n",
    "# 添加叙事分数列\n",
    "narrative_cols = {}\n",
    "for narrative in narrative_prototypes.keys():\n",
    "    narrative_cols[f'narrative_{narrative}'] = [r[narrative] for r in narrative_results]\n",
    "\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('primary_narrative', primary_narratives),\n",
    "    pl.Series('narrative_confidence', narrative_confidences),\n",
    "    *[pl.Series(k, v) for k, v in narrative_cols.items()]\n",
    "])\n",
    "\n",
    "print(f\"\\n✅ 叙事框架检测完成\")\n",
    "print(f\"\\n📊 叙事分布:\")\n",
    "print(df_sample.group_by('primary_narrative').agg(pl.len().alias('count')).sort('count', descending=True))\n",
    "\n",
    "print(f\"\\n📈 平均置信度: {np.mean([c for c in narrative_confidences if c > 0]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stance_header",
   "metadata": {},
   "source": [
    "## 步骤 4: 政治立场分类\n",
    "\n",
    "基于关键词的立场检测：\n",
    "- **conservative**: 保守派（支持Kirk、谴责暴力、捍卫保守价值）\n",
    "- **liberal**: 自由派（批评Kirk、反思言论、强调后果）\n",
    "- **neutral**: 中立（客观报道、学术分析、悼念）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stance_detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 开始政治立场分类...\n",
      "✅ 政治立场分类完成\n",
      "\n",
      "📊 立场分布:\n",
      "shape: (3, 2)\n",
      "┌──────────────────┬───────┐\n",
      "│ political_stance ┆ count │\n",
      "│ ---              ┆ ---   │\n",
      "│ str              ┆ u32   │\n",
      "╞══════════════════╪═══════╡\n",
      "│ neutral          ┆ 1843  │\n",
      "│ liberal          ┆ 88    │\n",
      "│ conservative     ┆ 69    │\n",
      "└──────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# 政治立场关键词\n",
    "stance_keywords = {\n",
    "    'conservative': [\n",
    "        r'\\bhero\\b', r'\\bpatriot\\b', r'\\bfreedom fighter\\b', r'\\bdefend\\w*\\b',\n",
    "        r'\\bMAGA\\b', r'\\bTrump\\b', r'\\bconservative movement\\b',\n",
    "        r'\\bleft\\w* violence\\b', r'\\bsocialist\\w*\\b', r'\\bliberal\\w* violence\\b',\n",
    "        r'\\bmarty\\w*\\b', r'\\bstanding up\\b'\n",
    "    ],\n",
    "    'liberal': [\n",
    "        r'\\bhateful\\b', r'\\btoxic\\b', r'\\bdangerous rhetoric\\b',\n",
    "        r'\\bextremis\\w*\\b', r'\\bhate speech\\b', r'\\bconsequences\\b',\n",
    "        r'\\bdeserve\\w*\\b', r'\\breap what\\b', r'\\bfar-right\\b',\n",
    "        r'\\bTurning Point\\b.*\\bnegative\\b'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def detect_stance(text):\n",
    "    \"\"\"检测政治立场\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    conservative_score = sum(1 for pattern in stance_keywords['conservative'] if re.search(pattern, text_lower))\n",
    "    liberal_score = sum(1 for pattern in stance_keywords['liberal'] if re.search(pattern, text_lower))\n",
    "    \n",
    "    if conservative_score > liberal_score and conservative_score > 0:\n",
    "        return 'conservative', conservative_score\n",
    "    elif liberal_score > conservative_score and liberal_score > 0:\n",
    "        return 'liberal', liberal_score\n",
    "    else:\n",
    "        return 'neutral', 0\n",
    "\n",
    "print(\"🎯 开始政治立场分类...\")\n",
    "stance_results = [detect_stance(t) for t in texts]\n",
    "stances = [r[0] for r in stance_results]\n",
    "stance_scores = [r[1] for r in stance_results]\n",
    "\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('political_stance', stances),\n",
    "    pl.Series('stance_confidence', stance_scores)\n",
    "])\n",
    "\n",
    "print(f\"✅ 政治立场分类完成\")\n",
    "print(f\"\\n📊 立场分布:\")\n",
    "print(df_sample.group_by('political_stance').agg(pl.len().alias('count')).sort('count', descending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal_header",
   "metadata": {},
   "source": [
    "## 步骤 5: 时间演变分析\n",
    "\n",
    "分析情感与叙事在5个时间窗口的演变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "temporal_evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 时间演变分析\n",
      "\n",
      "🎭 情感演变 (平均分数):\n",
      "shape: (1, 8)\n",
      "┌─────────────┬─────────────┬────────────┬───────────┬──────────┬────────────┬──────────┬──────────┐\n",
      "│ time_window ┆ tweet_count ┆ avg_sadnes ┆ avg_anger ┆ avg_fear ┆ avg_surpri ┆ avg_joy  ┆ avg_love │\n",
      "│ ---         ┆ ---         ┆ s          ┆ ---       ┆ ---      ┆ se         ┆ ---      ┆ ---      │\n",
      "│ str         ┆ u32         ┆ ---        ┆ f64       ┆ f64      ┆ ---        ┆ f64      ┆ f64      │\n",
      "│             ┆             ┆ f64        ┆           ┆          ┆ f64        ┆          ┆          │\n",
      "╞═════════════╪═════════════╪════════════╪═══════════╪══════════╪════════════╪══════════╪══════════╡\n",
      "│ 48-72h      ┆ 2000        ┆ 0.144821   ┆ 0.217268  ┆ 0.192494 ┆ 0.126924   ┆ 0.074406 ┆ 0.0      │\n",
      "└─────────────┴─────────────┴────────────┴───────────┴──────────┴────────────┴──────────┴──────────┘\n",
      "\n",
      "📖 叙事演变 (各时段top3叙事):\n",
      "\n",
      "  0-6h:\n",
      "\n",
      "  6-12h:\n",
      "\n",
      "  12-24h:\n",
      "\n",
      "  24-48h:\n",
      "\n",
      "  48-72h:\n",
      "    - political_violence: 950 条\n",
      "    - memorial: 660 条\n",
      "    - none: 236 条\n"
     ]
    }
   ],
   "source": [
    "print(\"📈 时间演变分析\")\n",
    "\n",
    "# 情感随时间演变\n",
    "emotion_evolution = df_sample.group_by('time_window').agg([\n",
    "    pl.len().alias('tweet_count'),\n",
    "    pl.col('emotion_sadness').mean().alias('avg_sadness'),\n",
    "    pl.col('emotion_anger').mean().alias('avg_anger'),\n",
    "    pl.col('emotion_fear').mean().alias('avg_fear'),\n",
    "    pl.col('emotion_surprise').mean().alias('avg_surprise'),\n",
    "    pl.col('emotion_joy').mean().alias('avg_joy'),\n",
    "    pl.col('emotion_love').mean().alias('avg_love')\n",
    "]).sort('time_window')\n",
    "\n",
    "print(\"\\n🎭 情感演变 (平均分数):\")\n",
    "print(emotion_evolution)\n",
    "\n",
    "# 叙事随时间演变\n",
    "narrative_evolution = df_sample.group_by(['time_window', 'primary_narrative']).agg(\n",
    "    pl.len().alias('count')\n",
    ").sort(['time_window', 'count'], descending=[False, True])\n",
    "\n",
    "print(\"\\n📖 叙事演变 (各时段top3叙事):\")\n",
    "for window in ['0-6h', '6-12h', '12-24h', '24-48h', '48-72h']:\n",
    "    top_narratives = narrative_evolution.filter(pl.col('time_window') == window).head(3)\n",
    "    print(f\"\\n  {window}:\")\n",
    "    for row in top_narratives.iter_rows(named=True):\n",
    "        print(f\"    - {row['primary_narrative']}: {row['count']} 条\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative_header",
   "metadata": {},
   "source": [
    "## 步骤 6: 提取代表性推文\n",
    "\n",
    "每类叙事选择2条最具代表性的推文（基于engagement和叙事得分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "representative_tweets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 提取代表性推文...\n",
      "\n",
      "✅ 代表性推文提取完成\n",
      "\n",
      "🏆 各叙事代表性推文（前100字符）:\n"
     ]
    }
   ],
   "source": [
    "print(\"📝 提取代表性推文...\")\n",
    "\n",
    "# 计算engagement分数\n",
    "df_sample = df_sample.with_columns(\n",
    "    (pl.col('retweetCount') + pl.col('likeCount') * 0.5 + pl.col('replyCount') * 0.3).alias('engagement_score')\n",
    ")\n",
    "\n",
    "representative_tweets = {}\n",
    "\n",
    "for narrative in narrative_keywords.keys():\n",
    "    # 筛选该叙事的推文\n",
    "    narrative_tweets = df_sample.filter(\n",
    "        (pl.col('primary_narrative') == narrative) &\n",
    "        (pl.col(f'narrative_{narrative}') >= 2)  # 至少匹配2个关键词\n",
    "    ).sort('engagement_score', descending=True).head(2)\n",
    "    \n",
    "    if narrative_tweets.height > 0:\n",
    "        representative_tweets[narrative] = narrative_tweets.select(['text', 'engagement_score', 'primary_emotion']).to_dicts()\n",
    "\n",
    "print(f\"\\n✅ 代表性推文提取完成\")\n",
    "print(f\"\\n🏆 各叙事代表性推文（前100字符）:\")\n",
    "for narrative, tweets in representative_tweets.items():\n",
    "    print(f\"\\n【{narrative.upper()}】\")\n",
    "    for i, tweet in enumerate(tweets, 1):\n",
    "        print(f\"  {i}. [{tweet['primary_emotion']}] {tweet['text'][:100]}...\")\n",
    "        print(f\"     Engagement: {tweet['engagement_score']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_header",
   "metadata": {},
   "source": [
    "## 步骤 7: 保存分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "save_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 内容分析结果已保存: ../parquet/content_analysis.parquet\n",
      "✅ 情感演变数据已保存: ../parquet/emotion_evolution.parquet\n",
      "✅ 叙事演变数据已保存: ../parquet/narrative_evolution.parquet\n",
      "\n",
      "📊 数据概览:\n",
      "  总分析推文数: 2,000\n",
      "  时间窗口数: 5\n",
      "  情感维度: 6\n",
      "  叙事框架: 6\n",
      "  政治立场: 3\n"
     ]
    }
   ],
   "source": [
    "from src import io\n",
    "\n",
    "# 保存完整的内容分析数据\n",
    "content_path = Path(\"../parquet/content_analysis.parquet\")\n",
    "io.materialize_parquet(df_sample.lazy(), content_path)\n",
    "print(f\"✅ 内容分析结果已保存: {content_path}\")\n",
    "\n",
    "# 保存情感演变数据\n",
    "emotion_evo_path = Path(\"../parquet/emotion_evolution.parquet\")\n",
    "io.materialize_parquet(emotion_evolution.lazy(), emotion_evo_path)\n",
    "print(f\"✅ 情感演变数据已保存: {emotion_evo_path}\")\n",
    "\n",
    "# 保存叙事演变数据\n",
    "narrative_evo_path = Path(\"../parquet/narrative_evolution.parquet\")\n",
    "io.materialize_parquet(narrative_evolution.lazy(), narrative_evo_path)\n",
    "print(f\"✅ 叙事演变数据已保存: {narrative_evo_path}\")\n",
    "\n",
    "# 保存代表性推文（转为DataFrame）\n",
    "repr_tweets_list = []\n",
    "for narrative, tweets in representative_tweets.items():\n",
    "    for tweet in tweets:\n",
    "        repr_tweets_list.append({\n",
    "            'narrative': narrative,\n",
    "            'text': tweet['text'],\n",
    "            'emotion': tweet['primary_emotion'],\n",
    "            'engagement': tweet['engagement_score']\n",
    "        })\n",
    "\n",
    "if repr_tweets_list:\n",
    "    repr_tweets_df = pl.DataFrame(repr_tweets_list)\n",
    "    repr_tweets_path = Path(\"../parquet/representative_tweets.parquet\")\n",
    "    io.materialize_parquet(repr_tweets_df.lazy(), repr_tweets_path)\n",
    "    print(f\"✅ 代表性推文已保存: {repr_tweets_path}\")\n",
    "\n",
    "print(f\"\\n📊 数据概览:\")\n",
    "print(f\"  总分析推文数: {df_sample.height:,}\")\n",
    "print(f\"  时间窗口数: 5\")\n",
    "print(f\"  情感维度: 6\")\n",
    "print(f\"  叙事框架: 6\")\n",
    "print(f\"  政治立场: 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ✅ 内容分析完成！\n",
    "\n",
    "**生成的核心数据**:\n",
    "- `content_analysis.parquet`: 完整的情感、叙事、立场分析结果\n",
    "- `emotion_evolution.parquet`: 6大情感随时间的演变\n",
    "- `narrative_evolution.parquet`: 6大叙事随时间的演变\n",
    "- `representative_tweets.parquet`: 各叙事的代表性推文\n",
    "\n",
    "**下一步**: \n",
    "1. 运行 `01_temporal_dynamics.ipynb` 生成小时级时间序列\n",
    "2. 构建可视化Dashboard展示所有洞察"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
