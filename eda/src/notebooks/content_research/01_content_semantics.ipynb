{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 03 内容分析：情感、叙事与政治立场\n",
    "\n",
    "**研究核心**: Charlie Kirk政治暗杀事件后72小时的社交媒体舆论内容分析\n",
    "\n",
    "**分析维度**:\n",
    "1. **6维情感分析**: sadness, anger, fear, surprise, disgust, joy\n",
    "2. **6大叙事框架**: 政治暴力受害者、言论后果、政治极化、言论自由、阴谋论、纪念遗产\n",
    "3. **政治立场分类**: conservative, liberal, neutral\n",
    "4. **时间演变**: 情感与叙事随72小时的变化\n",
    "5. **代表性内容**: 每类叙事的典型推文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python 路径已配置: /workspace\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 将项目根目录添加到 Python 路径\n",
    "project_root = Path('/workspace')\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "print(f\"✅ Python 路径已配置: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 步骤 1: 加载数据并采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据加载完成: 508,954 行\n",
      "📝 有效英文推文: 415,714 条\n",
      "  24-48h: 337,119 条 → 采样 2,000 条\n",
      "  48-72h: 78,595 条 → 采样 2,000 条\n",
      "\n",
      "📋 采样完成: 4,000 条推文\n",
      "\n",
      "时间窗口分布:\n",
      "shape: (2, 2)\n",
      "┌─────────────┬───────┐\n",
      "│ time_window ┆ count │\n",
      "│ ---         ┆ ---   │\n",
      "│ str         ┆ u32   │\n",
      "╞═════════════╪═══════╡\n",
      "│ 24-48h      ┆ 2000  │\n",
      "│ 48-72h      ┆ 2000  │\n",
      "└─────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 加载enriched数据（包含event_time_delta_hours和time_window字段）\n",
    "df = pl.read_parquet(\"../parquet/tweets_enriched.parquet\")\n",
    "print(f\"📊 数据加载完成: {df.height:,} 行\")\n",
    "\n",
    "# 过滤有效英文文本\n",
    "df_text = df.filter(\n",
    "    (pl.col('text').is_not_null()) & \n",
    "    (pl.col('lang') == 'en') &\n",
    "    (pl.col('text').str.len_chars() > 20)  # 至少20字符\n",
    ")\n",
    "print(f\"📝 有效英文推文: {df_text.height:,} 条\")\n",
    "\n",
    "# 采样策略：每个时间窗口采样最多20000条（确保时间演变分析的代表性）\n",
    "sample_per_window = 20000\n",
    "\n",
    "# 方法：对每个时间窗口分别采样后合并\n",
    "sampled_dfs = []\n",
    "for window in df_text['time_window'].unique().sort():\n",
    "    window_df = df_text.filter(pl.col('time_window') == window)\n",
    "    # 如果该窗口数据少于20000，全部使用；否则采样20000\n",
    "    n_sample = min(sample_per_window, window_df.height)\n",
    "    sampled = window_df.sample(n=n_sample, seed=42)\n",
    "    sampled_dfs.append(sampled)\n",
    "    print(f\"  {window}: {window_df.height:,} 条 → 采样 {n_sample:,} 条\")\n",
    "\n",
    "df_sample = pl.concat(sampled_dfs).sort('createdAt')\n",
    "\n",
    "print(f\"\\n📋 采样完成: {df_sample.height:,} 条推文\")\n",
    "print(f\"\\n时间窗口分布:\")\n",
    "print(df_sample.group_by('time_window').agg(pl.len().alias('count')).sort('time_window'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotion_header",
   "metadata": {},
   "source": [
    "## 步骤 2: 六维情感分析\n",
    "\n",
    "使用 HuggingFace `j-hartmann/emotion-english-distilroberta-base` 模型  \n",
    "分类：sadness, joy, love, anger, fear, surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emotion_analysis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 加载情感分析模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型加载完成 (device: CPU)\n",
      "\n",
      "🔄 开始情感分析 (4,000 条推文)...\n",
      "✅ 情感分析完成\n",
      "\n",
      "📊 情感分布:\n",
      "shape: (7, 2)\n",
      "┌─────────────────┬───────┐\n",
      "│ primary_emotion ┆ count │\n",
      "│ ---             ┆ ---   │\n",
      "│ str             ┆ u32   │\n",
      "╞═════════════════╪═══════╡\n",
      "│ anger           ┆ 1026  │\n",
      "│ neutral         ┆ 867   │\n",
      "│ fear            ┆ 821   │\n",
      "│ sadness         ┆ 543   │\n",
      "│ surprise        ┆ 333   │\n",
      "│ joy             ┆ 247   │\n",
      "│ disgust         ┆ 163   │\n",
      "└─────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(\"🤖 加载情感分析模型...\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    device=device,\n",
    "    top_k=None  # 返回所有情感的概率\n",
    ")\n",
    "\n",
    "print(f\"✅ 模型加载完成 (device: {'GPU' if device == 0 else 'CPU'})\")\n",
    "\n",
    "# 处理文本（批量推理）\n",
    "texts = df_sample['text'].to_list()\n",
    "print(f\"\\n🔄 开始情感分析 ({len(texts):,} 条推文)...\")\n",
    "\n",
    "# 批量处理，每批128条\n",
    "batch_size = 128\n",
    "all_emotions = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    # 截断长文本\n",
    "    batch_truncated = [t[:512] for t in batch]\n",
    "    results = emotion_classifier(batch_truncated)\n",
    "    all_emotions.extend(results)\n",
    "    \n",
    "    if (i + batch_size) % 1000 == 0:\n",
    "        print(f\"  处理进度: {i + batch_size:,} / {len(texts):,}\")\n",
    "\n",
    "print(f\"✅ 情感分析完成\")\n",
    "\n",
    "# 提取主要情感和置信度\n",
    "primary_emotions = [max(e, key=lambda x: x['score'])['label'] for e in all_emotions]\n",
    "primary_scores = [max(e, key=lambda x: x['score'])['score'] for e in all_emotions]\n",
    "\n",
    "# 提取6大情感的分数（构建情感向量）\n",
    "emotion_labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "emotion_vectors = {}\n",
    "for label in emotion_labels:\n",
    "    scores = []\n",
    "    for result in all_emotions:\n",
    "        score_dict = {item['label']: item['score'] for item in result}\n",
    "        scores.append(score_dict.get(label, 0.0))\n",
    "    emotion_vectors[f'emotion_{label}'] = scores\n",
    "\n",
    "# 添加到dataframe\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('primary_emotion', primary_emotions),\n",
    "    pl.Series('emotion_confidence', primary_scores),\n",
    "    *[pl.Series(k, v) for k, v in emotion_vectors.items()]\n",
    "])\n",
    "\n",
    "print(f\"\\n📊 情感分布:\")\n",
    "print(df_sample.group_by('primary_emotion').agg(pl.len().alias('count')).sort('count', descending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative_header",
   "metadata": {},
   "source": [
    "## 步骤 3: 六大叙事框架检测\n",
    "\n",
    "基于关键词和语义相似度的叙事分类：\n",
    "1. **political_violence**: 政治暴力受害者叙事\n",
    "2. **consequences**: 言论后果叙事\n",
    "3. **polarization**: 政治极化叙事\n",
    "4. **free_speech**: 言论自由叙事\n",
    "5. **conspiracy**: 阴谋论叙事\n",
    "6. **memorial**: 纪念与遗产叙事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "narrative_keywords",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 加载语义模型用于叙事检测...\n",
      "🔢 生成叙事框架语义向量...\n",
      "🔍 开始基于语义的叙事框架检测...\n",
      "  (使用sentence embeddings + 关键词增强)\n",
      "\n",
      "🔢 生成推文语义向量 (4,000 条)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 检测叙事框架...\n",
      "  处理进度: 2,000 / 4,000\n",
      "  处理进度: 4,000 / 4,000\n",
      "\n",
      "✅ 叙事框架检测完成\n",
      "\n",
      "📊 叙事分布:\n",
      "shape: (7, 2)\n",
      "┌────────────────────┬───────┐\n",
      "│ primary_narrative  ┆ count │\n",
      "│ ---                ┆ ---   │\n",
      "│ str                ┆ u32   │\n",
      "╞════════════════════╪═══════╡\n",
      "│ political_violence ┆ 1912  │\n",
      "│ memorial           ┆ 1234  │\n",
      "│ none               ┆ 485   │\n",
      "│ free_speech        ┆ 157   │\n",
      "│ consequences       ┆ 102   │\n",
      "│ conspiracy         ┆ 88    │\n",
      "│ polarization       ┆ 22    │\n",
      "└────────────────────┴───────┘\n",
      "\n",
      "📈 平均置信度: 0.465\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"🤖 加载语义模型用于叙事检测...\")\n",
    "# 复用之前的模型或加载轻量级模型\n",
    "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 定义6大叙事框架的原型文本（核心语义描述）\n",
    "narrative_prototypes = {\n",
    "    'political_violence': [\n",
    "        \"This is a tragic political assassination and act of violence\",\n",
    "        \"Charlie Kirk was a victim of political violence and murder\",\n",
    "        \"The shooting was a terrible attack on a political figure\",\n",
    "        \"This assassination is an act of terror against conservatives\"\n",
    "    ],\n",
    "    'consequences': [\n",
    "        \"His hateful rhetoric had dangerous consequences\",\n",
    "        \"This is the result of divisive and toxic speech\",\n",
    "        \"He deserves blame for spreading hate and division\",\n",
    "        \"His inflammatory words caused this violence\"\n",
    "    ],\n",
    "    'polarization': [\n",
    "        \"America is deeply divided and polarized\",\n",
    "        \"This shows our country is on the brink of civil war\",\n",
    "        \"We treat each other as enemies instead of fellow citizens\",\n",
    "        \"Political tribalism is tearing our nation apart\"\n",
    "    ],\n",
    "    'free_speech': [\n",
    "        \"This is an attack on free speech and open debate\",\n",
    "        \"They are trying to silence conservative voices\",\n",
    "        \"We must defend the right to express political views\",\n",
    "        \"Censorship and suppression of speech led to this\"\n",
    "    ],\n",
    "    'conspiracy': [\n",
    "        \"This was a false flag operation and setup\",\n",
    "        \"The deep state planned this assassination\",\n",
    "        \"This is a psyop to manipulate public opinion\",\n",
    "        \"The official story is fake and a coverup\"\n",
    "    ],\n",
    "    'memorial': [\n",
    "        \"We honor and remember Charlie Kirk's legacy\",\n",
    "        \"His impact on conservative youth will not be forgotten\",\n",
    "        \"Rest in peace, he made a difference in politics\",\n",
    "        \"We pay tribute to his memory and contributions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 生成叙事原型的embeddings（每个叙事用其原型文本的平均embedding）\n",
    "print(\"🔢 生成叙事框架语义向量...\")\n",
    "narrative_embeddings = {}\n",
    "for narrative, prototype_texts in narrative_prototypes.items():\n",
    "    proto_embs = semantic_model.encode(prototype_texts)\n",
    "    # 使用平均向量作为该叙事的代表\n",
    "    narrative_embeddings[narrative] = np.mean(proto_embs, axis=0)\n",
    "\n",
    "# 关键词辅助（用于增强confidence）\n",
    "narrative_keywords = {\n",
    "    'political_violence': [\n",
    "        r'\\bvictim\\b', r'\\btragedy\\b', r'\\bassassinat\\w*\\b', r'\\bviolence\\b', \n",
    "        r'\\bmurder\\w*\\b', r'\\bkill\\w*\\b', r'\\bshot\\b', r'\\bshooting\\b',\n",
    "        r'\\bterror\\w*\\b', r'\\bgunman\\b', r'\\battack\\w*\\b'\n",
    "    ],\n",
    "    'consequences': [\n",
    "        r'\\brhetoric\\b', r'\\bconsequences\\b', r'\\bhate speech\\b', r'\\bdivisive\\b',\n",
    "        r'\\bresponsib\\w*\\b', r'\\bblame\\b', r'\\bcaused\\b', r'\\bdeserve\\w*\\b',\n",
    "        r'\\bkarma\\b', r'\\breap\\w*\\b'\n",
    "    ],\n",
    "    'polarization': [\n",
    "        r'\\bdivided\\b', r'\\bpolari\\w*\\b', r'\\bcivil war\\b', r'\\benemy\\b',\n",
    "        r'\\bus vs them\\b', r'\\btear\\w* apart\\b', r'\\bpartisan\\b'\n",
    "    ],\n",
    "    'free_speech': [\n",
    "        r'\\bfree speech\\b', r'\\bsilenc\\w*\\b', r'\\bcensor\\w*\\b', r'\\bdebate\\b',\n",
    "        r'\\bfirst amendment\\b', r'\\bvoice\\b', r'\\bspeak\\w* out\\b'\n",
    "    ],\n",
    "    'conspiracy': [\n",
    "        r'\\bfalse flag\\b', r'\\bsetup\\b', r'\\bdeep state\\b', r'\\bpsyop\\b',\n",
    "        r'\\bcoverup\\b', r'\\bcover-up\\b', r'\\bplanned\\b', r'\\binside job\\b',\n",
    "        r'\\bfake\\b', r'\\bhoax\\b'\n",
    "    ],\n",
    "    'memorial': [\n",
    "        r'\\blegacy\\b', r'\\bremember\\b', r'\\bhonor\\b', r'\\bimpact\\b',\n",
    "        r'\\bRIP\\b', r'\\brest in peace\\b', r'\\bmemory\\b', r'\\bmemorial\\b',\n",
    "        r'\\btribute\\b', r'\\bmiss\\w*\\b'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def detect_narratives_semantic(text, text_embedding):\n",
    "    \"\"\"基于语义相似度 + 关键词增强的叙事检测\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    narrative_scores = {}\n",
    "    \n",
    "    for narrative in narrative_prototypes.keys():\n",
    "        # 1. 语义相似度分数（主要）\n",
    "        similarity = cosine_similarity(\n",
    "            text_embedding.reshape(1, -1),\n",
    "            narrative_embeddings[narrative].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        \n",
    "        # 2. 关键词匹配分数（辅助增强）\n",
    "        keyword_matches = sum(1 for pattern in narrative_keywords[narrative] \n",
    "                             if re.search(pattern, text_lower))\n",
    "        keyword_boost = keyword_matches * 0.05  # 每个关键词增加5%\n",
    "        \n",
    "        # 综合分数：语义相似度为主，关键词提供boost\n",
    "        final_score = similarity + keyword_boost\n",
    "        narrative_scores[narrative] = final_score\n",
    "    \n",
    "    return narrative_scores\n",
    "\n",
    "print(\"🔍 开始基于语义的叙事框架检测...\")\n",
    "print(\"  (使用sentence embeddings + 关键词增强)\")\n",
    "\n",
    "# 生成所有推文的embeddings（批量处理）\n",
    "print(f\"\\n🔢 生成推文语义向量 ({len(texts):,} 条)...\")\n",
    "tweet_embeddings = semantic_model.encode(texts, show_progress_bar=True, batch_size=128)\n",
    "\n",
    "# 对每条推文进行叙事检测\n",
    "print(\"\\n🎯 检测叙事框架...\")\n",
    "narrative_results = []\n",
    "for i, (text, embedding) in enumerate(zip(texts, tweet_embeddings)):\n",
    "    scores = detect_narratives_semantic(text, embedding)\n",
    "    narrative_results.append(scores)\n",
    "    \n",
    "    if (i + 1) % 2000 == 0:\n",
    "        print(f\"  处理进度: {i + 1:,} / {len(texts):,}\")\n",
    "\n",
    "# 提取主导叙事（得分最高的，且高于阈值0.3）\n",
    "primary_narratives = []\n",
    "narrative_confidences = []\n",
    "for scores in narrative_results:\n",
    "    max_narrative = max(scores, key=scores.get)\n",
    "    max_score = scores[max_narrative]\n",
    "    \n",
    "    if max_score > 0.3:  # 置信度阈值\n",
    "        primary_narratives.append(max_narrative)\n",
    "        narrative_confidences.append(max_score)\n",
    "    else:\n",
    "        primary_narratives.append('none')  # 无明显叙事\n",
    "        narrative_confidences.append(0.0)\n",
    "\n",
    "# 添加叙事分数列\n",
    "narrative_cols = {}\n",
    "for narrative in narrative_prototypes.keys():\n",
    "    narrative_cols[f'narrative_{narrative}'] = [r[narrative] for r in narrative_results]\n",
    "\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('primary_narrative', primary_narratives),\n",
    "    pl.Series('narrative_confidence', narrative_confidences),\n",
    "    *[pl.Series(k, v) for k, v in narrative_cols.items()]\n",
    "])\n",
    "\n",
    "print(f\"\\n✅ 叙事框架检测完成\")\n",
    "print(f\"\\n📊 叙事分布:\")\n",
    "print(df_sample.group_by('primary_narrative').agg(pl.len().alias('count')).sort('count', descending=True))\n",
    "\n",
    "print(f\"\\n📈 平均置信度: {np.mean([c for c in narrative_confidences if c > 0]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stance_header",
   "metadata": {},
   "source": [
    "## 步骤 4: 政治立场分类（优化升级）\n",
    "\n",
    "**【优化新增】混合立场分类策略**:\n",
    "1. **作者bio信号** (author_stance_prelabel) - 从作者历史立场推断\n",
    "2. **推文关键词匹配** - 推文内容的立场线索\n",
    "3. **情感-叙事联合推理** - 通过情感和叙事的组合推断立场\n",
    "\n",
    "**最终决策**: 三重信号加权融合，提高分类准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stance_detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 开始混合立场分类...\n",
      "  信号1: 作者bio预标注\n",
      "  信号2: 推文关键词匹配\n",
      "  信号3: 情感-叙事联合推理\n",
      "✅ 检测到作者bio预标注字段\n",
      "\n",
      "✅ 混合立场分类完成\n",
      "\n",
      "📊 【优化后】立场分布:\n",
      "shape: (3, 2)\n",
      "┌──────────────────┬───────┐\n",
      "│ political_stance ┆ count │\n",
      "│ ---              ┆ ---   │\n",
      "│ str              ┆ u32   │\n",
      "╞══════════════════╪═══════╡\n",
      "│ neutral          ┆ 3930  │\n",
      "│ liberal          ┆ 46    │\n",
      "│ conservative     ┆ 24    │\n",
      "└──────────────────┴───────┘\n",
      "\n",
      "📊 【对比】原纯关键词方法的分布:\n",
      "shape: (3, 2)\n",
      "┌──────────────────┬───────┐\n",
      "│ political_stance ┆ count │\n",
      "│ ---              ┆ ---   │\n",
      "│ str              ┆ u32   │\n",
      "╞══════════════════╪═══════╡\n",
      "│ neutral          ┆ 3624  │\n",
      "│ liberal          ┆ 243   │\n",
      "│ conservative     ┆ 133   │\n",
      "└──────────────────┴───────┘\n",
      "\n",
      "🎯 关键改进:\n",
      "  中立比例: 90.6% → 98.2%\n",
      "  有立场推文: 376 → 70 (+-306)\n"
     ]
    }
   ],
   "source": [
    "# 【优化升级】混合立场分类器\n",
    "\n",
    "# 1. 推文关键词信号（保留原有关键词，扩展覆盖）\n",
    "stance_keywords = {\n",
    "    'conservative': [\n",
    "        r'\\bhero\\b', r'\\bpatriot\\b', r'\\bfreedom fighter\\b', r'\\bdefend\\w*\\b',\n",
    "        r'\\bMAGA\\b', r'\\bTrump\\b', r'\\bconservative movement\\b',\n",
    "        r'\\bleft\\w* violence\\b', r'\\bsocialist\\w*\\b', r'\\bliberal\\w* violence\\b',\n",
    "        r'\\bmarty\\w*\\b', r'\\bstanding up\\b', r'\\bpray\\w* for\\b.*\\bfamily\\b',\n",
    "        r'\\bRIP\\b.*\\blegend\\b', r'\\bAmerica First\\b'\n",
    "    ],\n",
    "    'liberal': [\n",
    "        r'\\bhateful\\b', r'\\btoxic\\b', r'\\bdangerous rhetoric\\b',\n",
    "        r'\\bextremis\\w*\\b', r'\\bhate speech\\b', r'\\bconsequences\\b',\n",
    "        r'\\bdeserve\\w*\\b', r'\\breap what\\b', r'\\bfar-right\\b',\n",
    "        r'\\bTurning Point\\b.*\\bnegative\\b', r'\\bkarma\\b', r'\\bfinally\\b',\n",
    "        r'\\bspread\\w* hate\\b', r'\\bincit\\w*\\b'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def detect_stance_from_text(text: str) -> tuple[str, float]:\n",
    "    \"\"\"基于推文关键词检测立场\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    conservative_score = sum(1 for pattern in stance_keywords['conservative'] if re.search(pattern, text_lower))\n",
    "    liberal_score = sum(1 for pattern in stance_keywords['liberal'] if re.search(pattern, text_lower))\n",
    "    \n",
    "    if conservative_score > liberal_score and conservative_score > 0:\n",
    "        return 'conservative', min(conservative_score * 0.3, 1.0)\n",
    "    elif liberal_score > conservative_score and liberal_score > 0:\n",
    "        return 'liberal', min(liberal_score * 0.3, 1.0)\n",
    "    else:\n",
    "        return 'neutral', 0.0\n",
    "\n",
    "def infer_stance_from_emotion_narrative(emotion: str, narrative: str, \n",
    "                                       emotion_anger: float, emotion_sadness: float) -> tuple[str, float]:\n",
    "    \"\"\"基于情感-叙事组合推断立场\"\"\"\n",
    "    # 规则1: 批判性叙事 + 愤怒 → 自由派\n",
    "    if narrative == 'consequences' and emotion_anger > 0.25:\n",
    "        return 'liberal', 0.4\n",
    "    \n",
    "    # 规则2: 暴力受害者叙事 + 悲伤 → 保守派\n",
    "    if narrative == 'political_violence' and emotion_sadness > 0.2:\n",
    "        return 'conservative', 0.4\n",
    "    \n",
    "    # 规则3: 纪念叙事 + 悲伤 → 保守派倾向\n",
    "    if narrative == 'memorial' and emotion_sadness > 0.15:\n",
    "        return 'conservative', 0.3\n",
    "    \n",
    "    # 规则4: 言论自由叙事 → 保守派倾向\n",
    "    if narrative == 'free_speech':\n",
    "        return 'conservative', 0.35\n",
    "    \n",
    "    # 规则5: 阴谋论 + 愤怒 → 保守派极端\n",
    "    if narrative == 'conspiracy' and emotion_anger > 0.2:\n",
    "        return 'conservative', 0.3\n",
    "    \n",
    "    return 'neutral', 0.0\n",
    "\n",
    "def fuse_stance_signals(author_stance: str, author_conf: float,\n",
    "                       text_stance: str, text_conf: float,\n",
    "                       emotion_stance: str, emotion_conf: float) -> tuple[str, float]:\n",
    "    \"\"\"融合三重立场信号，加权投票\"\"\"\n",
    "    # 权重设置：作者bio > 推文关键词 > 情感叙事\n",
    "    weights = {\n",
    "        'author': 0.5,   # 作者历史立场最可靠\n",
    "        'text': 0.35,    # 推文内容次之\n",
    "        'emotion': 0.15  # 情感叙事辅助\n",
    "    }\n",
    "    \n",
    "    # 计算加权得分\n",
    "    scores = {'conservative': 0.0, 'liberal': 0.0, 'neutral': 0.0}\n",
    "    \n",
    "    # 作者信号\n",
    "    if author_stance != 'neutral' and author_conf > 0:\n",
    "        scores[author_stance] += weights['author'] * author_conf\n",
    "    \n",
    "    # 推文信号\n",
    "    if text_stance != 'neutral' and text_conf > 0:\n",
    "        scores[text_stance] += weights['text'] * text_conf\n",
    "    \n",
    "    # 情感叙事信号\n",
    "    if emotion_stance != 'neutral' and emotion_conf > 0:\n",
    "        scores[emotion_stance] += weights['emotion'] * emotion_conf\n",
    "    \n",
    "    # 决策：取最高分，需超过阈值0.15\n",
    "    max_stance = max(scores, key=scores.get)\n",
    "    max_score = scores[max_stance]\n",
    "    \n",
    "    if max_score > 0.15:\n",
    "        return max_stance, min(max_score, 1.0)\n",
    "    else:\n",
    "        return 'neutral', 0.0\n",
    "\n",
    "print(\"🎯 开始混合立场分类...\")\n",
    "print(\"  信号1: 作者bio预标注\")\n",
    "print(\"  信号2: 推文关键词匹配\")\n",
    "print(\"  信号3: 情感-叙事联合推理\")\n",
    "\n",
    "# 提取所需字段\n",
    "texts = df_sample['text'].to_list()\n",
    "\n",
    "# 【防御性检查】检查新增字段是否存在\n",
    "if 'author_stance_prelabel' in df_sample.columns and 'author_stance_confidence' in df_sample.columns:\n",
    "    author_stances = df_sample['author_stance_prelabel'].to_list()\n",
    "    author_confs = df_sample['author_stance_confidence'].to_list()\n",
    "    print(\"✅ 检测到作者bio预标注字段\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"⚠️  警告: 未找到 author_stance_prelabel 和 author_stance_confidence 字段\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n📋 原因分析:\")\n",
    "    print(\"   tweets_enriched.parquet 文件未包含新增字段\")\n",
    "    print(\"\\n🔧 解决方案:\")\n",
    "    print(\"   1. 确认已运行最新版本的 00_data_intake.ipynb\")\n",
    "    print(\"   2. 检查 00_data_intake.ipynb Step 6 是否成功执行（应该显示新字段）\")\n",
    "    print(\"   3. 验证 parquet 文件:\")\n",
    "    print(\"      import polars as pl\")\n",
    "    print(\"      df = pl.read_parquet('../parquet/tweets_enriched.parquet')\")\n",
    "    print(\"      print(df.columns)  # 检查是否包含 author_stance_prelabel\")\n",
    "    print(\"   4. 如果字段存在但仍报错，重启 Jupyter kernel 后重新运行\")\n",
    "    print(\"\\n⚙️  当前降级模式:\")\n",
    "    print(\"   使用 neutral 作为默认作者立场，仅启用信号2和信号3\")\n",
    "    print(\"   分类准确性会下降，建议修复后重新运行\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    author_stances = ['neutral'] * len(texts)\n",
    "    author_confs = [0.0] * len(texts)\n",
    "\n",
    "primary_emotions = df_sample['primary_emotion'].to_list()\n",
    "primary_narratives = df_sample['primary_narrative'].to_list()\n",
    "emotion_angers = df_sample['emotion_anger'].to_list()\n",
    "emotion_sadnesses = df_sample['emotion_sadness'].to_list()\n",
    "\n",
    "# 对每条推文进行三重信号融合\n",
    "final_stances = []\n",
    "final_confidences = []\n",
    "signal_details = []  # 用于调试和验证\n",
    "\n",
    "for i, (text, author_st, author_cf, emotion, narrative, anger, sadness) in enumerate(zip(\n",
    "    texts, author_stances, author_confs, primary_emotions, primary_narratives, \n",
    "    emotion_angers, emotion_sadnesses\n",
    ")):\n",
    "    # 信号1: 作者bio\n",
    "    # 处理空值：如果author_stance_prelabel是None，设为'neutral'\n",
    "    author_st = author_st if author_st is not None else 'neutral'\n",
    "    author_cf = author_cf if author_cf is not None else 0.0\n",
    "    \n",
    "    # 信号2: 推文关键词\n",
    "    text_st, text_cf = detect_stance_from_text(text)\n",
    "    \n",
    "    # 信号3: 情感-叙事\n",
    "    emotion_st, emotion_cf = infer_stance_from_emotion_narrative(emotion, narrative, anger, sadness)\n",
    "    \n",
    "    # 融合决策\n",
    "    final_st, final_cf = fuse_stance_signals(\n",
    "        author_st, author_cf,\n",
    "        text_st, text_cf,\n",
    "        emotion_st, emotion_cf\n",
    "    )\n",
    "    \n",
    "    final_stances.append(final_st)\n",
    "    final_confidences.append(final_cf)\n",
    "    signal_details.append({\n",
    "        'author': (author_st, author_cf),\n",
    "        'text': (text_st, text_cf),\n",
    "        'emotion': (emotion_st, emotion_cf)\n",
    "    })\n",
    "    \n",
    "    if (i + 1) % 5000 == 0:\n",
    "        print(f\"  处理进度: {i + 1:,} / {len(texts):,}\")\n",
    "\n",
    "# 添加到dataframe\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('political_stance', final_stances),\n",
    "    pl.Series('stance_confidence', final_confidences)\n",
    "])\n",
    "\n",
    "print(f\"\\n✅ 混合立场分类完成\")\n",
    "print(f\"\\n📊 【优化后】立场分布:\")\n",
    "new_dist = df_sample.group_by('political_stance').agg(pl.len().alias('count')).sort('count', descending=True)\n",
    "print(new_dist)\n",
    "\n",
    "# 对比原方法的结果（仅用关键词）\n",
    "print(f\"\\n📊 【对比】原纯关键词方法的分布:\")\n",
    "old_stances = [detect_stance_from_text(t)[0] for t in texts]\n",
    "old_dist = pl.DataFrame({'political_stance': old_stances}).group_by('political_stance').agg(pl.len().alias('count')).sort('count', descending=True)\n",
    "print(old_dist)\n",
    "\n",
    "print(f\"\\n🎯 关键改进:\")\n",
    "neutral_old = old_dist.filter(pl.col('political_stance') == 'neutral')['count'][0] if old_dist.filter(pl.col('political_stance') == 'neutral').height > 0 else 0\n",
    "neutral_new = new_dist.filter(pl.col('political_stance') == 'neutral')['count'][0] if new_dist.filter(pl.col('political_stance') == 'neutral').height > 0 else 0\n",
    "print(f\"  中立比例: {neutral_old/len(texts)*100:.1f}% → {neutral_new/len(texts)*100:.1f}%\")\n",
    "print(f\"  有立场推文: {len(texts) - neutral_old} → {len(texts) - neutral_new} (+{len(texts) - neutral_new - (len(texts) - neutral_old)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal_header",
   "metadata": {},
   "source": [
    "## 步骤 5: 时间演变分析\n",
    "\n",
    "分析情感与叙事在5个时间窗口的演变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "temporal_evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 时间演变分析\n",
      "\n",
      "🎭 情感演变 (平均分数):\n",
      "shape: (2, 8)\n",
      "┌─────────────┬─────────────┬────────────┬───────────┬──────────┬────────────┬──────────┬──────────┐\n",
      "│ time_window ┆ tweet_count ┆ avg_sadnes ┆ avg_anger ┆ avg_fear ┆ avg_surpri ┆ avg_joy  ┆ avg_love │\n",
      "│ ---         ┆ ---         ┆ s          ┆ ---       ┆ ---      ┆ se         ┆ ---      ┆ ---      │\n",
      "│ str         ┆ u32         ┆ ---        ┆ f64       ┆ f64      ┆ ---        ┆ f64      ┆ f64      │\n",
      "│             ┆             ┆ f64        ┆           ┆          ┆ f64        ┆          ┆          │\n",
      "╞═════════════╪═════════════╪════════════╪═══════════╪══════════╪════════════╪══════════╪══════════╡\n",
      "│ 24-48h      ┆ 2000        ┆ 0.141026   ┆ 0.233624  ┆ 0.214377 ┆ 0.106929   ┆ 0.069154 ┆ 0.0      │\n",
      "│ 48-72h      ┆ 2000        ┆ 0.144883   ┆ 0.25309   ┆ 0.176424 ┆ 0.121406   ┆ 0.062338 ┆ 0.0      │\n",
      "└─────────────┴─────────────┴────────────┴───────────┴──────────┴────────────┴──────────┴──────────┘\n",
      "\n",
      "📖 叙事演变 (各时段top3叙事):\n",
      "\n",
      "  0-6h:\n",
      "\n",
      "  6-12h:\n",
      "\n",
      "  12-24h:\n",
      "\n",
      "  24-48h:\n",
      "    - political_violence: 992 条\n",
      "    - memorial: 615 条\n",
      "    - none: 222 条\n",
      "\n",
      "  48-72h:\n",
      "    - political_violence: 920 条\n",
      "    - memorial: 619 条\n",
      "    - none: 263 条\n"
     ]
    }
   ],
   "source": [
    "print(\"📈 时间演变分析\")\n",
    "\n",
    "# 情感随时间演变\n",
    "emotion_evolution = df_sample.group_by('time_window').agg([\n",
    "    pl.len().alias('tweet_count'),\n",
    "    pl.col('emotion_sadness').mean().alias('avg_sadness'),\n",
    "    pl.col('emotion_anger').mean().alias('avg_anger'),\n",
    "    pl.col('emotion_fear').mean().alias('avg_fear'),\n",
    "    pl.col('emotion_surprise').mean().alias('avg_surprise'),\n",
    "    pl.col('emotion_joy').mean().alias('avg_joy'),\n",
    "    pl.col('emotion_love').mean().alias('avg_love')\n",
    "]).sort('time_window')\n",
    "\n",
    "print(\"\\n🎭 情感演变 (平均分数):\")\n",
    "print(emotion_evolution)\n",
    "\n",
    "# 叙事随时间演变\n",
    "narrative_evolution = df_sample.group_by(['time_window', 'primary_narrative']).agg(\n",
    "    pl.len().alias('count')\n",
    ").sort(['time_window', 'count'], descending=[False, True])\n",
    "\n",
    "print(\"\\n📖 叙事演变 (各时段top3叙事):\")\n",
    "for window in ['0-6h', '6-12h', '12-24h', '24-48h', '48-72h']:\n",
    "    top_narratives = narrative_evolution.filter(pl.col('time_window') == window).head(3)\n",
    "    print(f\"\\n  {window}:\")\n",
    "    for row in top_narratives.iter_rows(named=True):\n",
    "        print(f\"    - {row['primary_narrative']}: {row['count']} 条\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative_header",
   "metadata": {},
   "source": [
    "## 步骤 6: 提取代表性推文\n",
    "\n",
    "每类叙事选择2条最具代表性的推文（基于engagement和叙事得分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "representative_tweets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 提取代表性推文...\n",
      "\n",
      "✅ 代表性推文提取完成\n",
      "\n",
      "🏆 各叙事代表性推文（前100字符）:\n"
     ]
    }
   ],
   "source": [
    "print(\"📝 提取代表性推文...\")\n",
    "\n",
    "# 计算engagement分数\n",
    "df_sample = df_sample.with_columns(\n",
    "    (pl.col('retweetCount') + pl.col('likeCount') * 0.5 + pl.col('replyCount') * 0.3).alias('engagement_score')\n",
    ")\n",
    "\n",
    "representative_tweets = {}\n",
    "\n",
    "for narrative in narrative_keywords.keys():\n",
    "    # 筛选该叙事的推文\n",
    "    narrative_tweets = df_sample.filter(\n",
    "        (pl.col('primary_narrative') == narrative) &\n",
    "        (pl.col(f'narrative_{narrative}') >= 2)  # 至少匹配2个关键词\n",
    "    ).sort('engagement_score', descending=True).head(2)\n",
    "    \n",
    "    if narrative_tweets.height > 0:\n",
    "        representative_tweets[narrative] = narrative_tweets.select(['text', 'engagement_score', 'primary_emotion']).to_dicts()\n",
    "\n",
    "print(f\"\\n✅ 代表性推文提取完成\")\n",
    "print(f\"\\n🏆 各叙事代表性推文（前100字符）:\")\n",
    "for narrative, tweets in representative_tweets.items():\n",
    "    print(f\"\\n【{narrative.upper()}】\")\n",
    "    for i, tweet in enumerate(tweets, 1):\n",
    "        print(f\"  {i}. [{tweet['primary_emotion']}] {tweet['text'][:100]}...\")\n",
    "        print(f\"     Engagement: {tweet['engagement_score']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_header",
   "metadata": {},
   "source": [
    "## 步骤 7: 保存分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 内容分析结果已保存: ../parquet/content_analysis.parquet\n",
      "✅ 情感演变数据已保存: ../parquet/emotion_evolution.parquet\n",
      "✅ 叙事演变数据已保存: ../parquet/narrative_evolution.parquet\n",
      "\n",
      "📊 数据概览:\n",
      "  总分析推文数: 4,000\n",
      "  时间窗口数: 5\n",
      "  情感维度: 6\n",
      "  叙事框架: 6\n",
      "  政治立场: 3\n"
     ]
    }
   ],
   "source": [
    "from src import io\n",
    "\n",
    "# 保存完整的内容分析数据\n",
    "content_path = Path(\"../parquet/content_analysis.parquet\")\n",
    "io.materialize_parquet(df_sample.lazy(), content_path)\n",
    "print(f\"✅ 内容分析结果已保存: {content_path}\")\n",
    "\n",
    "# 保存情感演变数据\n",
    "emotion_evo_path = Path(\"../parquet/emotion_evolution.parquet\")\n",
    "io.materialize_parquet(emotion_evolution.lazy(), emotion_evo_path)\n",
    "print(f\"✅ 情感演变数据已保存: {emotion_evo_path}\")\n",
    "\n",
    "# 保存叙事演变数据\n",
    "narrative_evo_path = Path(\"../parquet/narrative_evolution.parquet\")\n",
    "io.materialize_parquet(narrative_evolution.lazy(), narrative_evo_path)\n",
    "print(f\"✅ 叙事演变数据已保存: {narrative_evo_path}\")\n",
    "\n",
    "# 保存代表性推文（转为DataFrame）\n",
    "repr_tweets_list = []\n",
    "for narrative, tweets in representative_tweets.items():\n",
    "    for tweet in tweets:\n",
    "        repr_tweets_list.append({\n",
    "            'narrative': narrative,\n",
    "            'text': tweet['text'],\n",
    "            'emotion': tweet['primary_emotion'],\n",
    "            'engagement': tweet['engagement_score']\n",
    "        })\n",
    "\n",
    "if repr_tweets_list:\n",
    "    repr_tweets_df = pl.DataFrame(repr_tweets_list)\n",
    "    repr_tweets_path = Path(\"../parquet/representative_tweets.parquet\")\n",
    "    io.materialize_parquet(repr_tweets_df.lazy(), repr_tweets_path)\n",
    "    print(f\"✅ 代表性推文已保存: {repr_tweets_path}\")\n",
    "\n",
    "print(f\"\\n📊 数据概览:\")\n",
    "print(f\"  总分析推文数: {df_sample.height:,}\")\n",
    "print(f\"  时间窗口数: 5\")\n",
    "print(f\"  情感维度: 6\")\n",
    "print(f\"  叙事框架: 6\")\n",
    "print(f\"  政治立场: 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ✅ 内容分析完成！\n",
    "\n",
    "**生成的核心数据**:\n",
    "- `content_analysis.parquet`: 完整的情感、叙事、立场分析结果\n",
    "- `emotion_evolution.parquet`: 6大情感随时间的演变\n",
    "- `narrative_evolution.parquet`: 6大叙事随时间的演变\n",
    "- `representative_tweets.parquet`: 各叙事的代表性推文\n",
    "\n",
    "**【优化新增】立场分类改进**:\n",
    "- ✅ 混合分类器：作者bio (50%) + 推文关键词 (35%) + 情感叙事 (15%)\n",
    "- ✅ 更准确的立场识别，减少误判为中立的比例\n",
    "- ✅ 保持向后兼容：输出字段与原版完全一致\n",
    "\n",
    "**下一步**: \n",
    "1. 运行 `02_temporal_evolution.ipynb` 生成小时级时间序列\n",
    "2. 【新增】运行 `03_author_profiling.ipynb` 分析作者画像与影响力\n",
    "3. 构建可视化Dashboard展示所有洞察"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
