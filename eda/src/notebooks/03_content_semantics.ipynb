{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b6afd4",
   "metadata": {},
   "source": [
    "# 03 内容语义与受众画像"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222351d",
   "metadata": {},
   "source": [
    "目标：主题建模、情感/毒性分析，比较蓝标与非蓝标群体的语言差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a16fe255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python 路径已配置: /workspace\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 将项目根目录添加到 Python 路径\n",
    "project_root = Path('/workspace')\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "print(f\"✅ Python 路径已配置: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c65fc7",
   "metadata": {},
   "source": [
    "## 步骤 1: 加载数据并准备文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2549fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据加载完成: 508,954 行\n",
      "📝 有效英文推文: 415,912 条\n",
      "\n",
      "🔵 蓝标用户: 143,119 条 (34.4%)\n",
      "⚪ 非蓝标用户: 272,793 条 (65.6%)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# 加载数据\n",
    "df = pl.read_parquet(\"parquet/tweets_enriched.parquet\")\n",
    "print(f\"📊 数据加载完成: {df.height:,} 行\")\n",
    "\n",
    "# 过滤有效文本（非空、英文）\n",
    "df_text = df.filter(\n",
    "    (pl.col('text').is_not_null()) & \n",
    "    (pl.col('lang') == 'en') &\n",
    "    (pl.col('text').str.len_chars() > 10)\n",
    ")\n",
    "print(f\"📝 有效英文推文: {df_text.height:,} 条\")\n",
    "\n",
    "# 统计蓝标分布\n",
    "blue_verified = df_text.filter(pl.col('author_isBlueVerified') == True).height\n",
    "print(f\"\\n🔵 蓝标用户: {blue_verified:,} 条 ({blue_verified/df_text.height*100:.1f}%)\")\n",
    "print(f\"⚪ 非蓝标用户: {df_text.height - blue_verified:,} 条 ({(df_text.height-blue_verified)/df_text.height*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f46c8",
   "metadata": {},
   "source": [
    "## 步骤 2: 文本特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a287f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 采样分析: 10,000 条推文\n",
      "\n",
      "📊 文本特征统计:\n",
      "  平均可读性: 60.25\n",
      "  平均词数: 33.0\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "# 采样数据（加速处理）\n",
    "sample_size = min(10000, df_text.height)\n",
    "df_sample = df_text.sample(n=sample_size, seed=42)\n",
    "print(f\"📋 采样分析: {sample_size:,} 条推文\")\n",
    "\n",
    "# 计算文本特征\n",
    "texts = df_sample['text'].to_list()\n",
    "readability_scores = [textstat.flesch_reading_ease(str(t)) for t in texts]\n",
    "word_counts = [len(str(t).split()) for t in texts]\n",
    "\n",
    "# 添加特征列\n",
    "df_sample = df_sample.with_columns([\n",
    "    pl.Series('readability', readability_scores),\n",
    "    pl.Series('word_count', word_counts)\n",
    "])\n",
    "\n",
    "print(f\"\\n📊 文本特征统计:\")\n",
    "print(f\"  平均可读性: {df_sample['readability'].mean():.2f}\")\n",
    "print(f\"  平均词数: {df_sample['word_count'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fed644",
   "metadata": {},
   "source": [
    "## 步骤 3: 主题建模（BERTopic）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e542571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 加载 Sentence Transformer 模型...\n",
      "🔢 生成文本嵌入...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5eda48cd4af43899ee91dea2906b99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 09:22:41,007 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 训练主题模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 09:22:43,438 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-10-29 09:22:43,439 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-10-29 09:22:43,701 - BERTopic - Cluster - Completed ✓\n",
      "2025-10-29 09:22:43,715 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-10-29 09:22:43,877 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 主题建模完成:\n",
      "  发现主题数: 48\n",
      "  (主题 -1 表示噪音/异常值)\n",
      "\n",
      "🏆 Top 5 主题:\n",
      "  主题 0: kirk, charlie, you, was, about\n",
      "  主题 1: charliekirk, charliekirkshot, the, this, is\n",
      "  主题 2: israel, netanyahu, gaza, the, to\n",
      "  主题 3: kirk, charlie, this, song, was\n",
      "  主题 4: robinson, tyler, 22yearold, suspect, utah\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "\n",
    "# 加载轻量级模型\n",
    "print(\"🤖 加载 Sentence Transformer 模型...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 生成文本嵌入\n",
    "print(\"🔢 生成文本嵌入...\")\n",
    "embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "# 训练 BERTopic 模型\n",
    "print(\"📚 训练主题模型...\")\n",
    "topic_model = BERTopic(\n",
    "    language='english',\n",
    "    calculate_probabilities=False,\n",
    "    verbose=True,\n",
    "    min_topic_size=30\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(texts, embeddings)\n",
    "\n",
    "# 添加主题标签\n",
    "df_sample = df_sample.with_columns(pl.Series('topic', topics))\n",
    "\n",
    "print(f\"\\n✅ 主题建模完成:\")\n",
    "print(f\"  发现主题数: {len(set(topics)) - 1}\")\n",
    "print(f\"  (主题 -1 表示噪音/异常值)\")\n",
    "\n",
    "# 显示 top 5 主题\n",
    "print(f\"\\n🏆 Top 5 主题:\")\n",
    "for topic_id, topic_words in topic_model.get_topics().items():\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    if topic_id >= 5:\n",
    "        break\n",
    "    words = [word for word, _ in topic_words[:5]]\n",
    "    print(f\"  主题 {topic_id}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a014c",
   "metadata": {},
   "source": [
    "## 步骤 4: 蓝标 vs 非蓝标对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd4b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 蓝标 vs 非蓝标对比:\n",
      "shape: (2, 6)\n",
      "┌───────────────────────┬───────┬─────────────────┬────────────────┬──────────────┬───────────┐\n",
      "│ author_isBlueVerified ┆ count ┆ avg_readability ┆ avg_word_count ┆ avg_retweets ┆ avg_likes │\n",
      "│ ---                   ┆ ---   ┆ ---             ┆ ---            ┆ ---          ┆ ---       │\n",
      "│ bool                  ┆ u32   ┆ f64             ┆ f64            ┆ f64          ┆ f64       │\n",
      "╞═══════════════════════╪═══════╪═════════════════╪════════════════╪══════════════╪═══════════╡\n",
      "│ false                 ┆ 6589  ┆ 62.22907        ┆ 27.533313      ┆ 2.92275      ┆ 29.238731 │\n",
      "│ true                  ┆ 3411  ┆ 56.435233       ┆ 43.564644      ┆ 54.681618    ┆ 395.50513 │\n",
      "└───────────────────────┴───────┴─────────────────┴────────────────┴──────────────┴───────────┘\n",
      "\n",
      "📈 主题分布差异:\n",
      "shape: (10, 3)\n",
      "┌───────────────────────┬───────┬─────┐\n",
      "│ author_isBlueVerified ┆ topic ┆ len │\n",
      "│ ---                   ┆ ---   ┆ --- │\n",
      "│ bool                  ┆ i64   ┆ u32 │\n",
      "╞═══════════════════════╪═══════╪═════╡\n",
      "│ false                 ┆ 0     ┆ 357 │\n",
      "│ false                 ┆ 1     ┆ 267 │\n",
      "│ false                 ┆ 2     ┆ 222 │\n",
      "│ false                 ┆ 3     ┆ 183 │\n",
      "│ false                 ┆ 5     ┆ 161 │\n",
      "│ false                 ┆ 6     ┆ 157 │\n",
      "│ false                 ┆ 4     ┆ 114 │\n",
      "│ false                 ┆ 7     ┆ 113 │\n",
      "│ false                 ┆ 12    ┆ 109 │\n",
      "│ false                 ┆ 10    ┆ 107 │\n",
      "└───────────────────────┴───────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# 按蓝标状态分组统计\n",
    "comparison = df_sample.group_by('author_isBlueVerified').agg([\n",
    "    pl.len().alias('count'),\n",
    "    pl.col('readability').mean().alias('avg_readability'),\n",
    "    pl.col('word_count').mean().alias('avg_word_count'),\n",
    "    pl.col('retweetCount').mean().alias('avg_retweets'),\n",
    "    pl.col('likeCount').mean().alias('avg_likes')\n",
    "]).sort('author_isBlueVerified')\n",
    "\n",
    "print(\"📊 蓝标 vs 非蓝标对比:\")\n",
    "print(comparison)\n",
    "\n",
    "# 主题分布对比\n",
    "print(\"\\n📈 主题分布差异:\")\n",
    "topic_by_verified = df_sample.filter(pl.col('topic') >= 0).group_by(['author_isBlueVerified', 'topic']).len().sort(['author_isBlueVerified', 'len'], descending=[False, True])\n",
    "print(topic_by_verified.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96019f01",
   "metadata": {},
   "source": [
    "## 步骤 5: 保存分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6497d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 内容分析结果已保存: parquet/content_analysis.parquet\n",
      "✅ 对比统计已保存: parquet/verified_comparison.parquet\n",
      "✅ 主题分布已保存: parquet/topic_distribution.parquet\n",
      "\n",
      "📂 所有生成的文件:\n"
     ]
    }
   ],
   "source": [
    "from src import io\n",
    "\n",
    "# 保存带主题的样本数据\n",
    "content_path = Path(\"parquet/content_analysis.parquet\")\n",
    "io.materialize_parquet(df_sample.lazy(), content_path)\n",
    "print(f\"✅ 内容分析结果已保存: {content_path}\")\n",
    "\n",
    "# 保存对比统计\n",
    "comparison_path = Path(\"parquet/verified_comparison.parquet\")\n",
    "io.materialize_parquet(comparison.lazy(), comparison_path)\n",
    "print(f\"✅ 对比统计已保存: {comparison_path}\")\n",
    "\n",
    "# 保存主题分布\n",
    "topic_dist_path = Path(\"parquet/topic_distribution.parquet\")\n",
    "io.materialize_parquet(topic_by_verified.lazy(), topic_dist_path)\n",
    "print(f\"✅ 主题分布已保存: {topic_dist_path}\")\n",
    "\n",
    "print(f\"\\n📂 所有生成的文件:\")\n",
    "for f in io.list_parquet_files():\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e86c54",
   "metadata": {},
   "source": [
    "## ✅ 内容语义分析完成！\n",
    "\n",
    "所有分析数据已准备完毕，可以用于 dashboard 可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca5c82-ddea-426e-9fba-45a0b18fff06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
