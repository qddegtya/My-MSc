{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e386af",
   "metadata": {},
   "source": [
    "# 00 数据接入与事件分析准备\n",
    "\n",
    "**研究背景**: Charlie Kirk政治暗杀事件社交媒体舆论分析  \n",
    "**事件时间**: 2025-09-10 枪击发生  \n",
    "**数据时间窗口**: 2025-09-11 23:55 至 2025-09-13 00:12 (事件后72小时)\n",
    "\n",
    "**目标**:\n",
    "1. 加载原始CSV数据并规范化类型\n",
    "2. 合并作者元数据\n",
    "3. **添加事件相关时间字段**（核心优化）\n",
    "4. 写入Parquet缓存供后续分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0419ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python 路径已配置: /workspace\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 将项目根目录添加到 Python 路径\n",
    "project_root = Path('/workspace')\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "print(f\"✅ Python 路径已配置: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578ec70",
   "metadata": {},
   "source": [
    "## 步骤 1: 加载原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2e15c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据 schema:\n",
      "Schema([('pseudo_id', Int64), ('text', String), ('retweetCount', Int64), ('replyCount', Int64), ('likeCount', Int64), ('quoteCount', Int64), ('viewCount', Int64), ('bookmarkCount', Int64), ('createdAt', String), ('lang', String), ('isReply', String), ('pseudo_conversationId', Int64), ('pseudo_inReplyToUsername', String), ('pseudo_author_userName', Int64), ('quoted_pseudo_id', String), ('author_isBlueVerified', String)])\n"
     ]
    }
   ],
   "source": [
    "from src import io, analysis, profiling\n",
    "import polars as pl\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# 加载原始推文数据 (LazyFrame)\n",
    "raw_lf = io.scan_raw_tweets()\n",
    "print(f\"📊 数据 schema:\")\n",
    "print(raw_lf.collect_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f67d4",
   "metadata": {},
   "source": [
    "## 步骤 2: 数据清洗与类型规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee8f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据加载完成: 508,954 行, 16 列\n",
      "✅ 布尔列规范化完成: ['isReply', 'author_isBlueVerified']\n",
      "✅ 时间字段转换完成\n"
     ]
    }
   ],
   "source": [
    "# 收集数据并规范化布尔列\n",
    "df = raw_lf.collect()\n",
    "print(f\"✅ 数据加载完成: {df.height:,} 行, {df.width} 列\")\n",
    "\n",
    "# 规范化布尔列\n",
    "bool_columns = ['isReply', 'author_isBlueVerified']\n",
    "df_cleaned = analysis.normalize_boolean_columns(df, bool_columns)\n",
    "print(f\"✅ 布尔列规范化完成: {bool_columns}\")\n",
    "\n",
    "# 转换时间字段为datetime类型\n",
    "df_cleaned = df_cleaned.with_columns(\n",
    "    pl.col('createdAt').str.to_datetime('%Y-%m-%d %H:%M:%S%#z').alias('createdAt')\n",
    ")\n",
    "print(f\"✅ 时间字段转换完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shooting_event",
   "metadata": {},
   "source": [
    "## 步骤 3: 添加事件相关时间字段（核心优化）\n",
    "\n",
    "**关键时间点**:\n",
    "- 枪击发生: 2025-09-10 (具体时间从数据推断)\n",
    "- 数据窗口: 事件后72小时内的社交媒体反应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "event_fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 数据时间范围分析:\n",
      "  最早推文: 2025-09-11 23:55:56+00:00\n",
      "  最晚推文: 2025-09-13 00:12:32+00:00\n",
      "  数据跨度: 24.3 小时\n",
      "\n",
      "🎯 枪击事件时间（推断）: 2025-09-10 20:00:00+00:00\n",
      "\n",
      "✅ 事件时间字段添加完成\n",
      "\n",
      "时段分布:\n",
      "shape: (2, 2)\n",
      "┌─────────────┬────────┐\n",
      "│ time_window ┆ count  │\n",
      "│ ---         ┆ ---    │\n",
      "│ str         ┆ u32    │\n",
      "╞═════════════╪════════╡\n",
      "│ 24-48h      ┆ 415075 │\n",
      "│ 48-72h      ┆ 93879  │\n",
      "└─────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 分析数据时间范围\n",
    "print(\"\\n📅 数据时间范围分析:\")\n",
    "min_time = df_cleaned['createdAt'].min()\n",
    "max_time = df_cleaned['createdAt'].max()\n",
    "print(f\"  最早推文: {min_time}\")\n",
    "print(f\"  最晚推文: {max_time}\")\n",
    "print(f\"  数据跨度: {(max_time - min_time).total_seconds() / 3600:.1f} 小时\")\n",
    "\n",
    "# 推断枪击发生时间（假设为数据开始前的某个时间点）\n",
    "# 根据数据最早时间推断：2025-09-11 23:55，枪击应该发生在9月10日\n",
    "# 保守估计：9月10日下午（美国山地时间），约UTC时间9月10日晚上\n",
    "SHOOTING_TIMESTAMP = datetime(2025, 9, 10, 20, 0, 0, tzinfo=timezone.utc)  # UTC时间\n",
    "print(f\"\\n🎯 枪击事件时间（推断）: {SHOOTING_TIMESTAMP}\")\n",
    "\n",
    "# 添加事件相关字段（修复：Polars datetime 是微秒精度，需要 * 1_000_000）\n",
    "df_with_event = df_cleaned.with_columns([\n",
    "    # 距离枪击事件的时间差（小时）\n",
    "    ((pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600).alias('event_time_delta_hours'),\n",
    "    \n",
    "    # 事件后时段标签\n",
    "    pl.when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 6\n",
    "    ).then(pl.lit('0-6h'))\n",
    "    .when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 12\n",
    "    ).then(pl.lit('6-12h'))\n",
    "    .when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 24\n",
    "    ).then(pl.lit('12-24h'))\n",
    "    .when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 48\n",
    "    ).then(pl.lit('24-48h'))\n",
    "    .otherwise(pl.lit('48-72h'))\n",
    "    .alias('time_window')\n",
    "])\n",
    "\n",
    "print(f\"\\n✅ 事件时间字段添加完成\")\n",
    "print(f\"\\n时段分布:\")\n",
    "print(df_with_event.group_by('time_window').agg(pl.len().alias('count')).sort('time_window'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e007ef6",
   "metadata": {},
   "source": [
    "## 步骤 4: 数据质量检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58352573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 缺失值统计 (top 5):\n",
      "shape: (5, 4)\n",
      "┌──────────────┬────────────┬────────────┬────────┐\n",
      "│ column       ┆ null_count ┆ null_ratio ┆ is_key │\n",
      "│ ---          ┆ ---        ┆ ---        ┆ ---    │\n",
      "│ str          ┆ i64        ┆ f64        ┆ bool   │\n",
      "╞══════════════╪════════════╪════════════╪════════╡\n",
      "│ pseudo_id    ┆ 0          ┆ 0.0        ┆ true   │\n",
      "│ text         ┆ 0          ┆ 0.0        ┆ true   │\n",
      "│ retweetCount ┆ 0          ┆ 0.0        ┆ false  │\n",
      "│ replyCount   ┆ 0          ┆ 0.0        ┆ false  │\n",
      "│ likeCount    ┆ 0          ┆ 0.0        ┆ false  │\n",
      "└──────────────┴────────────┴────────────┴────────┘\n",
      "\n",
      "🔍 重复推文数: 50\n"
     ]
    }
   ],
   "source": [
    "# 缺失值检查\n",
    "key_cols = ['pseudo_id', 'pseudo_author_userName', 'createdAt', 'text']\n",
    "missing_stats = profiling.missingness_summary(df_with_event, key_cols)\n",
    "print(\"📊 缺失值统计 (top 5):\")\n",
    "print(missing_stats.head(5))\n",
    "\n",
    "# 重复检查\n",
    "dupes = profiling.duplicate_check(df_with_event, ['pseudo_id'])\n",
    "print(f\"\\n🔍 重复推文数: {dupes.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c483149",
   "metadata": {},
   "source": [
    "## 步骤 5: 合并作者元数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652f8496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 作者元数据: 4242 位作者\n",
      "✅ 数据合并完成: 508,954 行, 25 列\n"
     ]
    }
   ],
   "source": [
    "# 加载作者信息\n",
    "authors_df = io.read_well_known_authors()\n",
    "print(f\"📋 作者元数据: {authors_df.height} 位作者\")\n",
    "\n",
    "# 类型转换：将 pseudo_author_userName 转为字符串以匹配 author_userName\n",
    "df_with_str_author = df_with_event.with_columns(\n",
    "    pl.col('pseudo_author_userName').cast(pl.Utf8).alias('pseudo_author_userName')\n",
    ")\n",
    "\n",
    "# 合并推文和作者数据（基于用户名）\n",
    "df_with_authors = df_with_str_author.join(\n",
    "    authors_df, \n",
    "    left_on='pseudo_author_userName', \n",
    "    right_on='author_userName',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"✅ 数据合并完成: {df_with_authors.height:,} 行, {df_with_authors.width} 列\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471acde2",
   "metadata": {},
   "source": [
    "## 步骤 6: 写入 Parquet 缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4c0293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parquet 文件已生成: parquet/tweets_enriched.parquet\n",
      "📁 文件大小: 58.37 MB\n",
      "\n",
      "新增字段:\n",
      "  - event_time_delta_hours: 距枪击事件的小时数\n",
      "  - time_window: 时段标签（0-6h, 6-12h, 12-24h, 24-48h, 48-72h）\n",
      "\n",
      "📊 事件时间字段示例:\n",
      "shape: (3, 4)\n",
      "┌─────────────────────────┬────────────────────────┬─────────────┬─────────────────────────────────┐\n",
      "│ createdAt               ┆ event_time_delta_hours ┆ time_window ┆ text                            │\n",
      "│ ---                     ┆ ---                    ┆ ---         ┆ ---                             │\n",
      "│ datetime[μs, UTC]       ┆ f64                    ┆ str         ┆ str                             │\n",
      "╞═════════════════════════╪════════════════════════╪═════════════╪═════════════════════════════════╡\n",
      "│ 2025-09-13 00:12:32 UTC ┆ 52.208889              ┆ 48-72h      ┆ CLEARLY WHY ROBINSO. KILLED CH… │\n",
      "│ 2025-09-13 00:12:32 UTC ┆ 52.208889              ┆ 48-72h      ┆ @695242549121979 Charlie Kirk … │\n",
      "│ 2025-09-13 00:12:32 UTC ┆ 52.208889              ┆ 48-72h      ┆ @396187379099632 @576794151260… │\n",
      "└─────────────────────────┴────────────────────────┴─────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 写入 parquet 文件供后续分析使用\n",
    "output_path = Path(\"parquet/tweets_enriched.parquet\")\n",
    "io.materialize_parquet(df_with_authors.lazy(), output_path)\n",
    "\n",
    "print(f\"✅ Parquet 文件已生成: {output_path}\")\n",
    "print(f\"📁 文件大小: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\n新增字段:\")\n",
    "print(f\"  - event_time_delta_hours: 距枪击事件的小时数\")\n",
    "print(f\"  - time_window: 时段标签（0-6h, 6-12h, 12-24h, 24-48h, 48-72h）\")\n",
    "\n",
    "# 验证新字段\n",
    "print(f\"\\n📊 事件时间字段示例:\")\n",
    "print(df_with_authors.select(['createdAt', 'event_time_delta_hours', 'time_window', 'text']).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66e626",
   "metadata": {},
   "source": [
    "## ✅ 数据接入完成！\n",
    "\n",
    "**新增核心字段**:\n",
    "- `event_time_delta_hours`: 距枪击事件的时间差（小时）\n",
    "- `time_window`: 事件后时段标签\n",
    "\n",
    "**下一步**: 运行 `03_content_semantics.ipynb` 进行情感与叙事分析"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
