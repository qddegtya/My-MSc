{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e386af",
   "metadata": {},
   "source": [
    "# 00 数据接入与事件分析准备\n",
    "\n",
    "**研究背景**: Charlie Kirk政治暗杀事件社交媒体舆论分析  \n",
    "**事件时间**: 2025-09-10 枪击发生  \n",
    "**数据时间窗口**: 2025-09-11 23:55 至 2025-09-13 00:12 (事件后72小时)\n",
    "\n",
    "**目标**:\n",
    "1. 加载原始CSV数据并规范化类型\n",
    "2. 合并作者元数据\n",
    "3. **添加事件相关时间字段**（核心优化）\n",
    "4. 写入Parquet缓存供后续分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0419ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python 路径已配置: /workspace\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 将项目根目录添加到 Python 路径\n",
    "project_root = Path('/workspace')\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "print(f\"✅ Python 路径已配置: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578ec70",
   "metadata": {},
   "source": [
    "## 步骤 1: 加载原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2e15c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据 schema:\n",
      "Schema([('pseudo_id', Int64), ('text', String), ('retweetCount', Int64), ('replyCount', Int64), ('likeCount', Int64), ('quoteCount', Int64), ('viewCount', Int64), ('bookmarkCount', Int64), ('createdAt', String), ('lang', String), ('isReply', String), ('pseudo_conversationId', Int64), ('pseudo_inReplyToUsername', String), ('pseudo_author_userName', Int64), ('quoted_pseudo_id', String), ('author_isBlueVerified', String)])\n"
     ]
    }
   ],
   "source": [
    "from src import io, analysis, profiling\n",
    "import polars as pl\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# 加载原始推文数据 (LazyFrame)\n",
    "raw_lf = io.scan_raw_tweets()\n",
    "print(f\"📊 数据 schema:\")\n",
    "print(raw_lf.collect_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f67d4",
   "metadata": {},
   "source": [
    "## 步骤 2: 数据清洗与类型规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee8f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据加载完成: 508,954 行, 16 列\n",
      "✅ 布尔列规范化完成: ['isReply', 'author_isBlueVerified']\n",
      "✅ 时间字段转换完成\n",
      "✅ pseudo_inReplyToUsername 类型转换完成: String -> Int64\n",
      "\n",
      "📊 关键字段类型验证:\n",
      "  pseudo_author_userName: Int64\n",
      "  pseudo_inReplyToUsername: Int64\n"
     ]
    }
   ],
   "source": [
    "# 收集数据并规范化布尔列\n",
    "df = raw_lf.collect()\n",
    "print(f\"✅ 数据加载完成: {df.height:,} 行, {df.width} 列\")\n",
    "\n",
    "# 规范化布尔列\n",
    "bool_columns = ['isReply', 'author_isBlueVerified']\n",
    "df_cleaned = analysis.normalize_boolean_columns(df, bool_columns)\n",
    "print(f\"✅ 布尔列规范化完成: {bool_columns}\")\n",
    "\n",
    "# 转换时间字段为datetime类型\n",
    "df_cleaned = df_cleaned.with_columns(\n",
    "    pl.col('createdAt').str.to_datetime('%Y-%m-%d %H:%M:%S%#z').alias('createdAt')\n",
    ")\n",
    "print(f\"✅ 时间字段转换完成\")\n",
    "\n",
    "# 【修复】转换 pseudo_inReplyToUsername 从 String 到 Int64\n",
    "# 空字符串转换为 null，然后转为 Int64\n",
    "df_cleaned = df_cleaned.with_columns(\n",
    "    pl.when(pl.col('pseudo_inReplyToUsername') == '')\n",
    "      .then(None)\n",
    "      .otherwise(pl.col('pseudo_inReplyToUsername'))\n",
    "      .cast(pl.Int64)\n",
    "      .alias('pseudo_inReplyToUsername')\n",
    ")\n",
    "print(f\"✅ pseudo_inReplyToUsername 类型转换完成: String -> Int64\")\n",
    "\n",
    "# 验证类型\n",
    "print(f\"\\n📊 关键字段类型验证:\")\n",
    "print(f\"  pseudo_author_userName: {df_cleaned['pseudo_author_userName'].dtype}\")\n",
    "print(f\"  pseudo_inReplyToUsername: {df_cleaned['pseudo_inReplyToUsername'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shooting_event",
   "metadata": {},
   "source": [
    "## 步骤 3: 添加事件相关时间字段（核心优化）\n",
    "\n",
    "**关键时间点**:\n",
    "- 枪击发生: 2025-09-10 (具体时间从数据推断)\n",
    "- 数据窗口: 事件后72小时内的社交媒体反应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "event_fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 数据时间范围分析:\n",
      "  最早推文: 2025-09-11 23:55:56+00:00\n",
      "  最晚推文: 2025-09-13 00:12:32+00:00\n",
      "  数据跨度: 24.3 小时\n",
      "\n",
      "🎯 枪击事件时间（推断）: 2025-09-10 20:00:00+00:00\n",
      "\n",
      "✅ 事件时间字段添加完成\n",
      "\n",
      "时段分布:\n",
      "shape: (2, 2)\n",
      "┌─────────────┬────────┐\n",
      "│ time_window ┆ count  │\n",
      "│ ---         ┆ ---    │\n",
      "│ str         ┆ u32    │\n",
      "╞═════════════╪════════╡\n",
      "│ 24-48h      ┆ 415075 │\n",
      "│ 48-72h      ┆ 93879  │\n",
      "└─────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# 分析数据时间范围\n",
    "print(\"\\n📅 数据时间范围分析:\")\n",
    "min_time = df_cleaned['createdAt'].min()\n",
    "max_time = df_cleaned['createdAt'].max()\n",
    "print(f\"  最早推文: {min_time}\")\n",
    "print(f\"  最晚推文: {max_time}\")\n",
    "print(f\"  数据跨度: {(max_time - min_time).total_seconds() / 3600:.1f} 小时\")\n",
    "\n",
    "# 推断枪击发生时间（假设为数据开始前的某个时间点）\n",
    "# 根据数据最早时间推断：2025-09-11 23:55，枪击应该发生在9月10日\n",
    "# 保守估计：9月10日下午（美国山地时间），约UTC时间9月10日晚上\n",
    "SHOOTING_TIMESTAMP = datetime(2025, 9, 10, 20, 0, 0, tzinfo=timezone.utc)  # UTC时间\n",
    "print(f\"\\n🎯 枪击事件时间（推断）: {SHOOTING_TIMESTAMP}\")\n",
    "\n",
    "# 添加事件相关字段（修复：Polars datetime 是微秒精度，需要 * 1_000_000）\n",
    "df_with_event = df_cleaned.with_columns([\n",
    "    # 距离枪击事件的时间差（小时）\n",
    "    ((pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600).alias('event_time_delta_hours'),\n",
    "    \n",
    "    # 事件后时段标签\n",
    "    pl.when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 6\n",
    "    ).then(pl.lit('0-6h'))\n",
    "    .when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 12\n",
    "    ).then(pl.lit('6-12h'))\n",
    "    .when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 24\n",
    "    ).then(pl.lit('12-24h'))\n",
    "    .when(\n",
    "        (pl.col('createdAt').cast(pl.Int64) - pl.lit(int(SHOOTING_TIMESTAMP.timestamp() * 1_000_000))) / 1_000_000 / 3600 < 48\n",
    "    ).then(pl.lit('24-48h'))\n",
    "    .otherwise(pl.lit('48-72h'))\n",
    "    .alias('time_window')\n",
    "])\n",
    "\n",
    "print(f\"\\n✅ 事件时间字段添加完成\")\n",
    "print(f\"\\n时段分布:\")\n",
    "print(df_with_event.group_by('time_window').agg(pl.len().alias('count')).sort('time_window'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e007ef6",
   "metadata": {},
   "source": [
    "## 步骤 4: 数据质量检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58352573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 缺失值统计 (top 5):\n",
      "shape: (5, 4)\n",
      "┌──────────────────────────┬────────────┬────────────┬────────┐\n",
      "│ column                   ┆ null_count ┆ null_ratio ┆ is_key │\n",
      "│ ---                      ┆ ---        ┆ ---        ┆ ---    │\n",
      "│ str                      ┆ i64        ┆ f64        ┆ bool   │\n",
      "╞══════════════════════════╪════════════╪════════════╪════════╡\n",
      "│ pseudo_inReplyToUsername ┆ 259862     ┆ 0.510581   ┆ false  │\n",
      "│ pseudo_id                ┆ 0          ┆ 0.0        ┆ true   │\n",
      "│ text                     ┆ 0          ┆ 0.0        ┆ true   │\n",
      "│ retweetCount             ┆ 0          ┆ 0.0        ┆ false  │\n",
      "│ replyCount               ┆ 0          ┆ 0.0        ┆ false  │\n",
      "└──────────────────────────┴────────────┴────────────┴────────┘\n",
      "\n",
      "🔍 重复推文数: 50\n"
     ]
    }
   ],
   "source": [
    "# 缺失值检查\n",
    "key_cols = ['pseudo_id', 'pseudo_author_userName', 'createdAt', 'text']\n",
    "missing_stats = profiling.missingness_summary(df_with_event, key_cols)\n",
    "print(\"📊 缺失值统计 (top 5):\")\n",
    "print(missing_stats.head(5))\n",
    "\n",
    "# 重复检查\n",
    "dupes = profiling.duplicate_check(df_with_event, ['pseudo_id'])\n",
    "print(f\"\\n🔍 重复推文数: {dupes.height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c483149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 测试作者立场提取:\n",
      "  Bio: MAGA supporter | America First | Pro-life Christia → conservative (conf: 0.60)\n",
      "  Bio: She/Her | BLM | Resist Trump | Climate Action Now  → liberal      (conf: 0.80)\n",
      "  Bio: Software engineer | Coffee lover | Cat dad         → neutral      (conf: 0.00)\n",
      "  Bio: None                                               → neutral      (conf: 0.00)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_author_stance_from_bio(bio: str) -> tuple[str, float]:\n",
    "    \"\"\"\n",
    "    从作者bio中提取政治立场预标注\n",
    "    \n",
    "    返回: (stance, confidence)\n",
    "    - stance: 'conservative' | 'liberal' | 'neutral'\n",
    "    - confidence: 0.0-1.0 (匹配的关键词数量决定)\n",
    "    \"\"\"\n",
    "    if bio is None or not isinstance(bio, str):\n",
    "        return 'neutral', 0.0\n",
    "    \n",
    "    bio_lower = bio.lower()\n",
    "    \n",
    "    # 保守派信号词\n",
    "    conservative_keywords = [\n",
    "        r'\\bmaga\\b', r'\\btrump\\b', r'\\bconservative\\b', r'\\bpatriot\\b',\n",
    "        r'\\bamerica first\\b', r'\\b2a\\b', r'\\bpro-life\\b', r'\\bpro life\\b',\n",
    "        r'\\bread\\w* maga\\b', r'\\bgod\\b.*\\bcountry\\b', r'\\brepublican\\b',\n",
    "        r'\\bright\\w* wing\\b', r'\\btea party\\b', r'\\bliberty\\b.*\\bfreedom\\b',\n",
    "        r'\\b#maga\\b', r'\\b#trump\\b', r'\\b#americafirst\\b'\n",
    "    ]\n",
    "    \n",
    "    # 自由派信号词\n",
    "    liberal_keywords = [\n",
    "        r'\\bresist\\b', r'\\bprogressive\\b', r'\\bliberal\\b', r'\\bdemocrat\\b',\n",
    "        r'\\bblm\\b', r'\\bblack lives matter\\b', r'\\bclimate action\\b',\n",
    "        r'\\blgbtq\\+?\\b', r'\\bshe/her\\b', r'\\bhe/him\\b', r'\\bthey/them\\b',\n",
    "        r'\\bdei\\b', r'\\bequity\\b', r'\\binclusion\\b', r'\\banti[- ]trump\\b',\n",
    "        r'\\b#resist\\b', r'\\b#blm\\b', r'\\b#metoo\\b', r'\\bleft\\w* activist\\b'\n",
    "    ]\n",
    "    \n",
    "    # 计数匹配\n",
    "    conservative_count = sum(1 for pattern in conservative_keywords if re.search(pattern, bio_lower))\n",
    "    liberal_count = sum(1 for pattern in liberal_keywords if re.search(pattern, bio_lower))\n",
    "    \n",
    "    # 决策逻辑\n",
    "    if conservative_count > liberal_count and conservative_count > 0:\n",
    "        return 'conservative', min(conservative_count * 0.2, 1.0)\n",
    "    elif liberal_count > conservative_count and liberal_count > 0:\n",
    "        return 'liberal', min(liberal_count * 0.2, 1.0)\n",
    "    else:\n",
    "        return 'neutral', 0.0\n",
    "\n",
    "# 测试函数\n",
    "test_bios = [\n",
    "    \"MAGA supporter | America First | Pro-life Christian\",\n",
    "    \"She/Her | BLM | Resist Trump | Climate Action Now\",\n",
    "    \"Software engineer | Coffee lover | Cat dad\",\n",
    "    None\n",
    "]\n",
    "\n",
    "print(\"🧪 测试作者立场提取:\")\n",
    "for bio in test_bios:\n",
    "    stance, conf = extract_author_stance_from_bio(bio)\n",
    "    print(f\"  Bio: {str(bio)[:50]:<50} → {stance:12} (conf: {conf:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fpqcm5rdql",
   "metadata": {},
   "source": [
    "## 步骤 5: 作者立场预标注（优化新增）\n",
    "\n",
    "**目标**: 从作者 bio 中提取政治立场信号，用于后续推文立场分类的辅助判断\n",
    "\n",
    "**方法**: 基于关键词匹配识别 conservative/liberal 信号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652f8496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 作者元数据: 4242 位作者\n",
      "\n",
      "🏷️  正在为作者添加立场预标注...\n",
      "✅ 作者立场预标注完成\n",
      "\n",
      "立场分布:\n",
      "shape: (3, 2)\n",
      "┌────────────────────────┬───────┐\n",
      "│ author_stance_prelabel ┆ count │\n",
      "│ ---                    ┆ ---   │\n",
      "│ str                    ┆ u32   │\n",
      "╞════════════════════════╪═══════╡\n",
      "│ neutral                ┆ 3733  │\n",
      "│ conservative           ┆ 441   │\n",
      "│ liberal                ┆ 68    │\n",
      "└────────────────────────┴───────┘\n",
      "\n",
      "有立场信号的作者: 509 / 4242 (12.0%)\n",
      "\n",
      "🔍 处理 JOIN KEY:\n",
      "  原始格式: ['@292512269517606', '@608765984246811', '@300496301105995']\n",
      "  转换后: [292512269517606, 608765984246811, 300496301105995]\n",
      "  推文示例: [683805731746893, 772698505691224, 62423919865749]\n",
      "\n",
      "✅ 数据合并完成: 508,954 行, 28 列\n",
      "\n",
      "📊 立场标注覆盖:\n",
      "  有立场标注的推文数: 44,854 / 508,954 (8.8%)\n",
      "  有立场信号的推文数: 3,132 (0.6%)\n"
     ]
    }
   ],
   "source": [
    "# 加载作者信息\n",
    "authors_df = io.read_well_known_authors()\n",
    "print(f\"📋 作者元数据: {authors_df.height} 位作者\")\n",
    "\n",
    "# 【优化新增】为作者添加立场预标注\n",
    "print(f\"\\n🏷️  正在为作者添加立场预标注...\")\n",
    "stance_results = [\n",
    "    extract_author_stance_from_bio(bio) \n",
    "    for bio in authors_df['author_profile_bio_description'].to_list()\n",
    "]\n",
    "stances = [r[0] for r in stance_results]\n",
    "confidences = [r[1] for r in stance_results]\n",
    "\n",
    "authors_df = authors_df.with_columns([\n",
    "    pl.Series('author_stance_prelabel', stances),\n",
    "    pl.Series('author_stance_confidence', confidences)\n",
    "])\n",
    "\n",
    "print(f\"✅ 作者立场预标注完成\")\n",
    "print(f\"\\n立场分布:\")\n",
    "stance_dist = authors_df.group_by('author_stance_prelabel').agg(pl.len().alias('count')).sort('count', descending=True)\n",
    "print(stance_dist)\n",
    "print(f\"\\n有立场信号的作者: {authors_df.filter(pl.col('author_stance_confidence') > 0).height} / {authors_df.height} ({authors_df.filter(pl.col('author_stance_confidence') > 0).height / authors_df.height * 100:.1f}%)\")\n",
    "\n",
    "# 【关键修复】处理 obfuscated_userName\n",
    "# 去掉 @ 前缀并转换为 Int64\n",
    "print(f\"\\n🔍 处理 JOIN KEY:\")\n",
    "print(f\"  原始格式: {authors_df['obfuscated_userName'].head(3).to_list()}\")\n",
    "\n",
    "authors_df = authors_df.with_columns(\n",
    "    pl.col('obfuscated_userName')\n",
    "      .str.strip_prefix('@')\n",
    "      .cast(pl.Int64)\n",
    "      .alias('obfuscated_userName_int')\n",
    ")\n",
    "\n",
    "print(f\"  转换后: {authors_df['obfuscated_userName_int'].head(3).to_list()}\")\n",
    "print(f\"  推文示例: {df_with_event['pseudo_author_userName'].head(3).to_list()}\")\n",
    "\n",
    "# JOIN\n",
    "df_with_authors = df_with_event.join(\n",
    "    authors_df,\n",
    "    left_on='pseudo_author_userName',\n",
    "    right_on='obfuscated_userName_int',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ 数据合并完成: {df_with_authors.height:,} 行, {df_with_authors.width} 列\")\n",
    "\n",
    "# 【验证】检查覆盖率\n",
    "labeled_count = df_with_authors.filter(pl.col('author_stance_prelabel').is_not_null()).height\n",
    "print(f\"\\n📊 立场标注覆盖:\")\n",
    "print(f\"  有立场标注的推文数: {labeled_count:,} / {df_with_authors.height:,} ({labeled_count / df_with_authors.height * 100:.1f}%)\")\n",
    "if labeled_count > 0:\n",
    "    with_signal = df_with_authors.filter(pl.col('author_stance_confidence') > 0).height\n",
    "    print(f\"  有立场信号的推文数: {with_signal:,} ({with_signal / df_with_authors.height * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471acde2",
   "metadata": {},
   "source": [
    "## 步骤 6: 写入 Parquet 缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4c0293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 保存路径: /workspace/src/notebooks/parquet/tweets_enriched.parquet\n",
      "   (统一目录: /workspace/src/notebooks/parquet)\n",
      "\n",
      "✅ Parquet 文件已生成: /workspace/src/notebooks/parquet/tweets_enriched.parquet\n",
      "📁 文件大小: 59.05 MB\n",
      "\n",
      "新增字段:\n",
      "  - event_time_delta_hours: 距枪击事件的小时数\n",
      "  - time_window: 事件后时段标签（0-6h, 6-12h, 12-24h, 24-48h, 48-72h）\n",
      "  - author_stance_prelabel: 作者立场预标注 (conservative/liberal/neutral)\n",
      "  - author_stance_confidence: 立场预标注置信度 (0.0-1.0)\n",
      "\n",
      "📊 验证保存的字段:\n",
      "  保存前列数: 28\n",
      "  应包含字段: event_time_delta_hours, time_window, author_stance_prelabel, author_stance_confidence\n",
      "\n",
      "✅ 验证读取:\n",
      "  读取后列数: 28\n",
      "\n",
      "✅ 所有必需字段都已保存\n",
      "\n",
      "📊 作者立场字段示例:\n",
      "shape: (5, 4)\n",
      "┌────────────────────────┬────────────────────────┬────────────────────────┬───────────────────────┐\n",
      "│ pseudo_author_userName ┆ author_stance_prelabel ┆ author_stance_confiden ┆ text                  │\n",
      "│ ---                    ┆ ---                    ┆ ce                     ┆ ---                   │\n",
      "│ i64                    ┆ str                    ┆ ---                    ┆ str                   │\n",
      "│                        ┆                        ┆ f64                    ┆                       │\n",
      "╞════════════════════════╪════════════════════════╪════════════════════════╪═══════════════════════╡\n",
      "│ 683805731746893        ┆ null                   ┆ null                   ┆ CLEARLY WHY ROBINSO.  │\n",
      "│                        ┆                        ┆                        ┆ KILLED CH…            │\n",
      "│ 772698505691224        ┆ null                   ┆ null                   ┆ @695242549121979      │\n",
      "│                        ┆                        ┆                        ┆ Charlie Kirk …        │\n",
      "│ 62423919865749         ┆ null                   ┆ null                   ┆ @396187379099632      │\n",
      "│                        ┆                        ┆                        ┆ @576794151260…        │\n",
      "│ 23702770839054         ┆ null                   ┆ null                   ┆ @805230134765227      │\n",
      "│                        ┆                        ┆                        ┆ @718955815577…        │\n",
      "│ 686884260868392        ┆ null                   ┆ null                   ┆ Here’s a reality of   │\n",
      "│                        ┆                        ┆                        ┆ dealing wi…           │\n",
      "└────────────────────────┴────────────────────────┴────────────────────────┴───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 写入 parquet 文件供后续分析使用\n",
    "# 【修复】使用统一的 parquet 目录，而不是各 notebook 自己的目录\n",
    "output_path = io.PARQUET_DIR / \"tweets_enriched.parquet\"\n",
    "print(f\"📁 保存路径: {output_path}\")\n",
    "print(f\"   (统一目录: {io.PARQUET_DIR})\")\n",
    "\n",
    "io.materialize_parquet(df_with_authors.lazy(), output_path)\n",
    "\n",
    "print(f\"\\n✅ Parquet 文件已生成: {output_path}\")\n",
    "print(f\"📁 文件大小: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\n新增字段:\")\n",
    "print(f\"  - event_time_delta_hours: 距枪击事件的小时数\")\n",
    "print(f\"  - time_window: 事件后时段标签（0-6h, 6-12h, 12-24h, 24-48h, 48-72h）\")\n",
    "print(f\"  - author_stance_prelabel: 作者立场预标注 (conservative/liberal/neutral)\")\n",
    "print(f\"  - author_stance_confidence: 立场预标注置信度 (0.0-1.0)\")\n",
    "\n",
    "# 验证新字段\n",
    "print(f\"\\n📊 验证保存的字段:\")\n",
    "print(f\"  保存前列数: {df_with_authors.width}\")\n",
    "print(f\"  应包含字段: event_time_delta_hours, time_window, author_stance_prelabel, author_stance_confidence\")\n",
    "\n",
    "# 读取验证\n",
    "df_verify = pl.read_parquet(output_path)\n",
    "print(f\"\\n✅ 验证读取:\")\n",
    "print(f\"  读取后列数: {df_verify.width}\")\n",
    "\n",
    "# 检查关键字段\n",
    "required_fields = ['author_stance_prelabel', 'author_stance_confidence', 'event_time_delta_hours', 'time_window']\n",
    "missing_fields = [f for f in required_fields if f not in df_verify.columns]\n",
    "if missing_fields:\n",
    "    print(f\"\\n❌ 警告: 以下字段缺失 - {missing_fields}\")\n",
    "else:\n",
    "    print(f\"\\n✅ 所有必需字段都已保存\")\n",
    "    # 显示作者立场字段示例\n",
    "    print(f\"\\n📊 作者立场字段示例:\")\n",
    "    print(df_verify.select(['pseudo_author_userName', 'author_stance_prelabel', 'author_stance_confidence', 'text']).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66e626",
   "metadata": {},
   "source": [
    "## ✅ 数据接入完成！\n",
    "\n",
    "**新增核心字段**:\n",
    "- `event_time_delta_hours`: 距枪击事件的时间差（小时）\n",
    "- `time_window`: 事件后时段标签\n",
    "- **【优化新增】** `author_stance_prelabel`: 作者立场预标注 (conservative/liberal/neutral)\n",
    "- **【优化新增】** `author_stance_confidence`: 立场预标注置信度 (0.0-1.0)\n",
    "\n",
    "**下一步**: 运行 `01_content_semantics.ipynb` 进行情感与叙事分析（将使用author立场辅助分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa00be-328e-4837-a477-478ff9d6071d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
